{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mamoro98/Cuda-Programming/blob/main/Omer-Practical_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CUDA Programming on NVIDIA GPUs, July 22-26, 2024**\n",
        "\n",
        "# **Practical 2**\n",
        "\n",
        "Again make sure the correct Runtime is being used, by clicking on the Runtime option at the top, then \"Change runtime type\", and selecting an appropriate GPU such as the T4.\n",
        "\n",
        "Then verify with the instruction below the details of the GPU which is available to you.  "
      ],
      "metadata": {
        "id": "i1JlUA_e44zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uboEpcMD4xYA",
        "outputId": "61bee242-ff69-4c84-a9ed-41992b4fd59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul 27 09:31:18 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "First we upload two header files from the course webpage."
      ],
      "metadata": {
        "id": "nlO6dHwW7gRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv1nyjTmTmr7",
        "outputId": "a699a6e5-186f-4179-f982-6e0b712081f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-27 09:31:24--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34238 (33K) [text/x-chdr]\n",
            "Saving to: ‘helper_cuda.h’\n",
            "\n",
            "helper_cuda.h       100%[===================>]  33.44K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-07-27 09:31:25 (246 KB/s) - ‘helper_cuda.h’ saved [34238/34238]\n",
            "\n",
            "--2024-07-27 09:31:25--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23960 (23K) [text/x-chdr]\n",
            "Saving to: ‘helper_string.h’\n",
            "\n",
            "helper_string.h     100%[===================>]  23.40K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-07-27 09:31:25 (170 KB/s) - ‘helper_string.h’ saved [23960/23960]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "The next step is to create the file prac2.cu."
      ],
      "metadata": {
        "id": "RD6IjBwY2Ltm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac2.cu\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// GPU version of Monte Carlo algorithm using NVIDIA's CURAND library\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <curand.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CUDA global constants\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__constant__ int   N;\n",
        "__constant__ float T, r, sigma, rho, alpha, dt, con1, con2;\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "\n",
        "__global__ void pathcalc(float *d_z, float *d_v)\n",
        "{\n",
        "  float s1, s2, y1, y2, payoff;\n",
        "  int   ind;\n",
        "\n",
        "  // move array pointers to correct position\n",
        "\n",
        "  // version 1\n",
        "  ind = threadIdx.x + 2*N*blockIdx.x*blockDim.x;\n",
        "\n",
        "  // version 2\n",
        "  // ind = 2*N*threadIdx.x + 2*N*blockIdx.x*blockDim.x;\n",
        "\n",
        "\n",
        "  // path calculation\n",
        "\n",
        "  s1 = 1.0f;\n",
        "  s2 = 1.0f;\n",
        "\n",
        "  for (int n=0; n<N; n++) {\n",
        "    y1   = d_z[ind];\n",
        "    // version 1\n",
        "    ind += blockDim.x;      // shift pointer to next element\n",
        "    // version 2\n",
        "    // ind += 1;\n",
        "\n",
        "    y2   = rho*y1 + alpha*d_z[ind];\n",
        "    // version 1\n",
        "    ind += blockDim.x;      // shift pointer to next element\n",
        "    // version 2\n",
        "    // ind += 1;\n",
        "\n",
        "    s1 = s1*(con1 + con2*y1);\n",
        "    s2 = s2*(con1 + con2*y2);\n",
        "  }\n",
        "\n",
        "  // put payoff value into device array\n",
        "\n",
        "  payoff = 0.0f;\n",
        "  if ( fabs(s1-1.0f)<0.1f && fabs(s2-1.0f)<0.1f ) payoff = exp(-r*T);\n",
        "\n",
        "  d_v[threadIdx.x + blockIdx.x*blockDim.x] = payoff;\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int     NPATH=9600000, h_N=100;\n",
        "  float   h_T, h_r, h_sigma, h_rho, h_alpha, h_dt, h_con1, h_con2;\n",
        "  float  *h_v, *d_v, *d_z;\n",
        "  double  sum1, sum2;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory on host and device\n",
        "\n",
        "  h_v = (float *)malloc(sizeof(float)*NPATH);\n",
        "\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_v, sizeof(float)*NPATH) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_z, sizeof(float)*2*h_N*NPATH) );\n",
        "\n",
        "  // define constants and transfer to GPU\n",
        "\n",
        "  h_T     = 1.0f;\n",
        "  h_r     = 0.05f;\n",
        "  h_sigma = 0.1f;\n",
        "  h_rho   = 0.5f;\n",
        "  h_alpha = sqrt(1.0f-h_rho*h_rho);\n",
        "  h_dt    = 1.0f/h_N;\n",
        "  h_con1  = 1.0f + h_r*h_dt;\n",
        "  h_con2  = sqrt(h_dt)*h_sigma;\n",
        "\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(N,    &h_N,    sizeof(h_N)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(T,    &h_T,    sizeof(h_T)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(r,    &h_r,    sizeof(h_r)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(sigma,&h_sigma,sizeof(h_sigma)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(rho,  &h_rho,  sizeof(h_rho)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(alpha,&h_alpha,sizeof(h_alpha)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(dt,   &h_dt,   sizeof(h_dt)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(con1, &h_con1, sizeof(h_con1)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(con2, &h_con2, sizeof(h_con2)) );\n",
        "\n",
        "  // random number generation\n",
        "\n",
        "  curandGenerator_t gen;\n",
        "  checkCudaErrors( curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT) );\n",
        "  checkCudaErrors( curandSetPseudoRandomGeneratorSeed(gen, 1234ULL) );\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( curandGenerateNormal(gen, d_z, 2*h_N*NPATH, 0.0f, 1.0f) );\n",
        "  cudaEventRecord(stop);\n",
        "\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "  printf(\"CURAND normal RNG  execution time (ms): %f,  samples/sec: %e \\n\",\n",
        "          milli, 2.0*h_N*NPATH/(0.001*milli));\n",
        "\n",
        "  // execute kernel and time it\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  pathcalc<<<NPATH/128, 128>>>(d_z, d_v);\n",
        "  cudaEventRecord(stop);\n",
        "\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "  getLastCudaError(\"pathcalc execution failed\\n\");\n",
        "  printf(\"Monte Carlo kernel execution time (ms): %f \\n\",milli);\n",
        "\n",
        "  // copy back results\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(h_v, d_v, sizeof(float)*NPATH,\n",
        "                   cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // compute average\n",
        "\n",
        "  sum1 = 0.0;\n",
        "  sum2 = 0.0;\n",
        "  for (int i=0; i<NPATH; i++) {\n",
        "    sum1 += h_v[i];\n",
        "    sum2 += h_v[i]*h_v[i];\n",
        "  }\n",
        "\n",
        "  printf(\"\\nAverage value and standard deviation of error  = %13.8f %13.8f\\n\\n\",\n",
        "\t sum1/NPATH, sqrt((sum2/NPATH - (sum1/NPATH)*(sum1/NPATH))/NPATH) );\n",
        "\n",
        "  // Tidy up library\n",
        "\n",
        "  checkCudaErrors( curandDestroyGenerator(gen) );\n",
        "\n",
        "  // Release memory and exit cleanly\n",
        "\n",
        "  free(h_v);\n",
        "  checkCudaErrors( cudaFree(d_v) );\n",
        "  checkCudaErrors( cudaFree(d_z) );\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcwQANS22i3Q",
        "outputId": "b5fc148b-9687-4adc-8292-bed5dca9a93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prac2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "We can now compile and run the executable.  Note that the compilation links in the CUDA random number generation library cuRAND.\n"
      ],
      "metadata": {
        "id": "yds03ug532rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac2.cu -o prac2 -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart -lcurand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFHWm4Dd3_hw",
        "outputId": "3bb6bacf-32bd-4d07-c52c-67d4c03efb93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem, 36 bytes cmem[3]\n",
            "ptxas info    : Compiling entry function '_Z8pathcalcPfS_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z8pathcalcPfS_\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 368 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7jX9dSAaLj0",
        "outputId": "53640d01-e4cd-487e-a708-6bd94af29aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CURAND normal RNG  execution time (ms): 159.294525,  samples/sec: 1.205314e+10 \n",
            "Monte Carlo kernel execution time (ms): 29.521761 \n",
            "\n",
            "Average value and standard deviation of error  =    0.41786269    0.00015237\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "By going back to the previous code block you can modify the code to complete the Practical 2 exercises as prescribed in the Instructions for this practical.\n",
        "\n",
        "It is perhaps better to copy the Code cell (on my system this is done by using the mouse right-click) and paste it to form a new Code cell, so that the original cell uses Version 1, and the new cell uses Version 2.  You can then make a further copy when you do the new application for the final step in the practical.\n",
        "\n",
        "Remember to first make your own copy of the notebook so that you are able to edit it.\n",
        "\n",
        "For students doing this as an assignment to be assessed, you should add your name to the title of the notebook (as in \"Practical 2 -- Mike Giles.ipynb\"), make it shared (see the Share option in the top-right corner) and provide the shared link as the submission mechanism.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Lastly, the instructions below create, compile and execute a version of the code which generates the random numbers on-the-fly within each kernel using the device-level cuRAND library.  This gives the very best performance because the random numbers no longer are being transferred between the GPU and the device memory.\n"
      ],
      "metadata": {
        "id": "ncymVLmd4L82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac2_device.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// GPU version of Monte Carlo algorithm using NVIDIA's CURAND library\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <curand_kernel.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CUDA global constants\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__constant__ int   N;\n",
        "__constant__ float T, r, sigma, rho, alpha, dt, con1, con2;\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel routines -- see sections 3.5, 3.6 in cuRAND documentation\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void RNG_init(curandState *state)\n",
        "{\n",
        "  // RNG initialisation with id-based skipahead\n",
        "  int id = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  curand_init(1234, id, 0, &state[id]);\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void pathcalc(curandState *device_state, float *d_v,\n",
        "                         int mpath, int NPATH)\n",
        "{\n",
        "  float s1, s2, y1, y2, payoff;\n",
        "\n",
        "  int id = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  curandState_t state = device_state[id];\n",
        "\n",
        "  for(int m=0; m<mpath; m++) {\n",
        "    s1 = 1.0f;\n",
        "    s2 = 1.0f;\n",
        "\n",
        "    for (int n=0; n<N; n++) {\n",
        "      y1 = curand_normal(&state);\n",
        "      y2 = rho*y1 + alpha*curand_normal(&state);\n",
        "\n",
        "      s1 = s1*(con1 + con2*y1);\n",
        "      s2 = s2*(con1 + con2*y2);\n",
        "    }\n",
        "\n",
        "    // put payoff value into device array\n",
        "\n",
        "    payoff = 0.0f;\n",
        "    if ( fabs(s1-1.0f)<0.1f && fabs(s2-1.0f)<0.1f ) payoff = exp(-r*T);\n",
        "\n",
        "    int payoff_id = id + m*gridDim.x*blockDim.x;\n",
        "    if (payoff_id < NPATH) d_v[payoff_id] = payoff;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int     NPATH=9600000, h_N=100;\n",
        "  float   h_T, h_r, h_sigma, h_rho, h_alpha, h_dt, h_con1, h_con2;\n",
        "  float  *h_v, *d_v;\n",
        "  double  sum1, sum2;\n",
        "  curandState *state;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory on host and device\n",
        "\n",
        "  h_v = (float *)malloc(sizeof(float)*NPATH);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_v, sizeof(float)*NPATH) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&state, sizeof(curandState)*NPATH) );\n",
        "\n",
        "  // printf(\"size of curandState is %d bytes\\n\",sizeof(curandState));\n",
        "\n",
        "  // define constants and transfer to GPU\n",
        "\n",
        "  h_T     = 1.0f;\n",
        "  h_r     = 0.05f;\n",
        "  h_sigma = 0.1f;\n",
        "  h_rho   = 0.5f;\n",
        "  h_alpha = sqrt(1.0f-h_rho*h_rho);\n",
        "  h_dt    = 1.0f/h_N;\n",
        "  h_con1  = 1.0f + h_r*h_dt;\n",
        "  h_con2  = sqrt(h_dt)*h_sigma;\n",
        "\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(N,    &h_N,    sizeof(h_N)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(T,    &h_T,    sizeof(h_T)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(r,    &h_r,    sizeof(h_r)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(sigma,&h_sigma,sizeof(h_sigma)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(rho,  &h_rho,  sizeof(h_rho)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(alpha,&h_alpha,sizeof(h_alpha)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(dt,   &h_dt,   sizeof(h_dt)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(con1, &h_con1, sizeof(h_con1)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(con2, &h_con2, sizeof(h_con2)) );\n",
        "\n",
        "  // calculate theoretical occupancy -- see Pro Tip blog article:\n",
        "  // https://developer.nvidia.com/blog/cuda-pro-tip-occupancy-api-simplifies-launch-configuration/\n",
        "\n",
        "  int device;\n",
        "  cudaDeviceProp props;\n",
        "  cudaGetDevice(&device);\n",
        "  cudaGetDeviceProperties(&props, device);\n",
        "\n",
        "  int maxActiveBlocks, blockSize=128;\n",
        "  cudaOccupancyMaxActiveBlocksPerMultiprocessor( &maxActiveBlocks,\n",
        "                                                 pathcalc, blockSize, 0);\n",
        "  printf(\"maxActiveBlocks/SM = %d \\n\",maxActiveBlocks);\n",
        "  printf(\"number of SMs      = %d \\n\",props.multiProcessorCount);\n",
        "  int blocks = maxActiveBlocks*props.multiProcessorCount;\n",
        "\n",
        "  // execute kernels\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  RNG_init<<<blocks, 128>>>(state);\n",
        "  cudaEventRecord(stop);\n",
        "\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "  getLastCudaError(\"RNG_init execution failed\\n\");\n",
        "  printf(\"RNG_init kernel execution time (ms): %f \\n\",milli);\n",
        "\n",
        "  int paths_per_thread = (NPATH-1)/(128*blocks) + 1;\n",
        "  cudaEventRecord(start);\n",
        "  pathcalc<<<blocks, 128>>>(state,d_v,paths_per_thread,NPATH);\n",
        "  cudaEventRecord(stop);\n",
        "\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "  getLastCudaError(\"pathcalc execution failed\\n\");\n",
        "  printf(\"pathcalc kernel execution time (ms): %f \\n\",milli);\n",
        "\n",
        "  // copy back results\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(h_v, d_v, sizeof(float)*NPATH,\n",
        "                   cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // compute average\n",
        "\n",
        "  sum1 = 0.0;\n",
        "  sum2 = 0.0;\n",
        "  for (int i=0; i<NPATH; i++) {\n",
        "    sum1 += h_v[i];\n",
        "    sum2 += h_v[i]*h_v[i];\n",
        "  }\n",
        "\n",
        "  printf(\"\\nAverage value and standard deviation of error  = %13.8f %13.8f\\n\\n\",\n",
        "\t sum1/NPATH, sqrt((sum2/NPATH - (sum1/NPATH)*(sum1/NPATH))/NPATH) );\n",
        "\n",
        "  // Release memory and exit cleanly\n",
        "\n",
        "  free(h_v);\n",
        "  checkCudaErrors( cudaFree(d_v) );\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8xscLewbPlF",
        "outputId": "4e3ffe28-49f6-4414-80fd-c4081d377bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prac2_device.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac2_device.cu -o prac2_device -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart -lcurand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzGXiohVT5OR",
        "outputId": "640db67d-9d63-4076-d632-6ee3009502dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 218048 bytes gmem, 108 bytes cmem[3]\n",
            "ptxas info    : Compiling entry function '_Z8pathcalcP17curandStateXORWOWPfii' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z8pathcalcP17curandStateXORWOWPfii\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 29 registers, 376 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z8RNG_initP17curandStateXORWOW' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z8RNG_initP17curandStateXORWOW\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 32 registers, 360 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac2_device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsfyCekjazPh",
        "outputId": "d60e1bd4-dbbc-4de6-a2cd-3fca69e17943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxActiveBlocks/SM = 8 \n",
            "number of SMs      = 40 \n",
            "RNG_init kernel execution time (ms): 1.660928 \n",
            "pathcalc kernel execution time (ms): 23.816608 \n",
            "\n",
            "Average value and standard deviation of error  =    0.41802440    0.00015237\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again the final piece of code is to terminate the runtime."
      ],
      "metadata": {
        "id": "Fa5hiDuchY7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "Q8twCtvWhd9q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}