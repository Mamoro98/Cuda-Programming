{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mamoro98/Cuda-Programming/blob/main/Practical_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CUDA Programming on NVIDIA GPUs, July 22-26, 2024**\n",
        "\n",
        "# **Practical 1**\n",
        "\n",
        "First of all, make sure the correct Runtime is being used, by clicking on the Runtime option at the top, then \"Change runtime type\", selecting an appropriate GPU such as the T4, then clicking Save.\n",
        "\n",
        "A Colab Pro or Pro+ account will allow you to use a more powerful GPU, but the freely available T4 is perfectly adequate for the practicals in this course. It has good single precision capabilities and corresponds to Compute Capability 7.5.\n",
        "\n",
        "To check that this has been done successfully, the first instruction below returns information on the version of the available NVIDIA compiler, and the second instruction returns information on the GPU which is available to you.  \n",
        "\n",
        "To \"execute\" each cell, click on the little triangle to the left of the instructions.  The ! tells Colab that these are system commands to be executed."
      ],
      "metadata": {
        "id": "i1JlUA_e44zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uboEpcMD4xYA",
        "outputId": "5d9dcfbb-2ea2-4503-a7f6-1fea5f2ecb19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnJ21Z177Tc2",
        "outputId": "865a48ea-4977-4061-a500-78daad1767dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 12 06:02:33 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "The first step is to upload two header files from the course webpage."
      ],
      "metadata": {
        "id": "nlO6dHwW7gRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv1nyjTmTmr7",
        "outputId": "ca240614-1764-4c67-9f96-a7119f6b0f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-12 06:02:41--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27832 (27K) [text/x-chdr]\n",
            "Saving to: ‘helper_cuda.h’\n",
            "\n",
            "helper_cuda.h       100%[===================>]  27.18K   157KB/s    in 0.2s    \n",
            "\n",
            "2024-12-12 06:02:43 (157 KB/s) - ‘helper_cuda.h’ saved [27832/27832]\n",
            "\n",
            "--2024-12-12 06:02:43--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14875 (15K) [text/x-chdr]\n",
            "Saving to: ‘helper_string.h’\n",
            "\n",
            "helper_string.h     100%[===================>]  14.53K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-12-12 06:02:44 (368 KB/s) - ‘helper_string.h’ saved [14875/14875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "Next we create the file prac1a.cu by using the %%writefile instruction at the top of the code block.\n",
        "\n",
        "In doing this, we are following the helpful information provided here:\n",
        "https://colab.research.google.com/drive/1GJOfTp56OeQRdE4u2_S7pUNRcJb4ik9X?usp=sharing"
      ],
      "metadata": {
        "id": "FqvXt9br-gW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac1a.cu\n",
        "\n",
        "//\n",
        "// include files\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "//\n",
        "// kernel routine\n",
        "//\n",
        "\n",
        "__global__ void my_first_kernel(float *x)\n",
        "{\n",
        "  int tid = threadIdx.x + blockDim.x*blockIdx.x;\n",
        "\n",
        "  x[tid] = (float) threadIdx.x;\n",
        "}\n",
        "\n",
        "\n",
        "//\n",
        "// main code\n",
        "//\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "  float *h_x, *d_x;\n",
        "  int   nblocks, nthreads, nsize, n;\n",
        "\n",
        "  // set number of blocks, and threads per block\n",
        "\n",
        "  nblocks  = 2;\n",
        "  nthreads = 8;\n",
        "  nsize    = nblocks*nthreads ;\n",
        "\n",
        "  // allocate memory for array\n",
        "\n",
        "  h_x = (float *)malloc(nsize*sizeof(float));\n",
        "  cudaMalloc((void **)&d_x, nsize*sizeof(float));\n",
        "\n",
        "  // execute kernel\n",
        "\n",
        "  my_first_kernel<<<nblocks,nthreads>>>(d_x);\n",
        "\n",
        "  // copy back results and print them out\n",
        "\n",
        "  cudaMemcpy(h_x,d_x,nsize*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\n",
        "  for (n=0; n<nsize; n++) printf(\" n,  x  =  %d  %f \\n\",n,h_x[n]);\n",
        "\n",
        "  // free memory\n",
        "\n",
        "  cudaFree(d_x);\n",
        "  free(h_x);\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcwQANS22i3Q",
        "outputId": "4359bd51-f3e8-4090-9632-63145d07adde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prac1a.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "We use the following instruction to compile prac1a.cu to create the executable output prac1a.  The other flags are as follows:\n",
        "\n",
        "-I. says to look in the current directory for header files\n",
        "\n",
        "-lineinfo helps with debugging if there's a run-time problem\n",
        "\n",
        "-arch=sm_70 says it is for GPUs of Compute Capability 7.0 or later\n",
        "\n",
        "--ptxas=-v gives us additional information such as how many registers are used\n",
        "\n",
        "--use_fast_math generates faster code which might sometimes be a little less accurate\n",
        "\n",
        "-lcudart links in the run-time CUDA library\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWTkuuk_arY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac1a.cu -o prac1a -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HObz_6vOa8P1",
        "outputId": "964432f4-f393-445c-af0c-5d1baffc41f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z15my_first_kernelPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z15my_first_kernelPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 10 registers, 360 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Now we can execute the code.\n"
      ],
      "metadata": {
        "id": "Ku927eQ01g4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac1a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm0vvMosUm3C",
        "outputId": "5aafefb0-39d4-4a63-e164-17ee78189f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " n,  x  =  0  0.000000 \n",
            " n,  x  =  1  1.000000 \n",
            " n,  x  =  2  2.000000 \n",
            " n,  x  =  3  3.000000 \n",
            " n,  x  =  4  4.000000 \n",
            " n,  x  =  5  5.000000 \n",
            " n,  x  =  6  6.000000 \n",
            " n,  x  =  7  7.000000 \n",
            " n,  x  =  8  0.000000 \n",
            " n,  x  =  9  1.000000 \n",
            " n,  x  =  10  2.000000 \n",
            " n,  x  =  11  3.000000 \n",
            " n,  x  =  12  4.000000 \n",
            " n,  x  =  13  5.000000 \n",
            " n,  x  =  14  6.000000 \n",
            " n,  x  =  15  7.000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "We can now perform the same steps for the second code, prac1b.cu, which does lots of error-checking."
      ],
      "metadata": {
        "id": "yds03ug532rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac1b.cu\n",
        "\n",
        "//\n",
        "// include files\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "\n",
        "//\n",
        "// kernel routine\n",
        "//\n",
        "\n",
        "__global__ void my_first_kernel(float *x)\n",
        "{\n",
        "  int tid = threadIdx.x + blockDim.x*blockIdx.x;\n",
        "\n",
        "  x[tid] = (float) threadIdx.x;\n",
        "}\n",
        "\n",
        "\n",
        "//\n",
        "// main code\n",
        "//\n",
        "\n",
        "int main(int argc, const char **argv)\n",
        "{\n",
        "  float *h_x, *d_x;\n",
        "  int   nblocks, nthreads, nsize, n;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // set number of blocks, and threads per block\n",
        "\n",
        "  nblocks  = 2;\n",
        "  nthreads = 8;\n",
        "  nsize    = nblocks*nthreads ;\n",
        "\n",
        "  // allocate memory for array\n",
        "\n",
        "  h_x = (float *)malloc(nsize*sizeof(float));\n",
        "  checkCudaErrors(cudaMalloc((void **)&d_x, nsize*sizeof(float)));\n",
        "\n",
        "  // execute kernel\n",
        "\n",
        "  my_first_kernel<<<nblocks,nthreads>>>(d_x);\n",
        "  getLastCudaError(\"my_first_kernel execution failed\\n\");\n",
        "\n",
        "  // copy back results and print them out\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(h_x,d_x,nsize*sizeof(float),\n",
        "                 cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  for (n=0; n<nsize; n++) printf(\" n,  x  =  %d  %f \\n\",n,h_x[n]);\n",
        "\n",
        "  // free memory\n",
        "\n",
        "  checkCudaErrors(cudaFree(d_x));\n",
        "  free(h_x);\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbac7bfb-0e66-4895-b90a-4f4757e086da",
        "id": "vThsmRu7_7Zh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prac1b.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac1b.cu -o prac1b -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcYvbrFvAEM-",
        "outputId": "dd89d47b-e6f6-4611-f106-7e33740e854c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z15my_first_kernelPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z15my_first_kernelPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 10 registers, 360 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac1b"
      ],
      "metadata": {
        "id": "XFHWm4Dd3_hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ef9b67-5237-48f1-9a9a-d8a3006821b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            " n,  x  =  0  0.000000 \n",
            " n,  x  =  1  1.000000 \n",
            " n,  x  =  2  2.000000 \n",
            " n,  x  =  3  3.000000 \n",
            " n,  x  =  4  4.000000 \n",
            " n,  x  =  5  5.000000 \n",
            " n,  x  =  6  6.000000 \n",
            " n,  x  =  7  7.000000 \n",
            " n,  x  =  8  0.000000 \n",
            " n,  x  =  9  1.000000 \n",
            " n,  x  =  10  2.000000 \n",
            " n,  x  =  11  3.000000 \n",
            " n,  x  =  12  4.000000 \n",
            " n,  x  =  13  5.000000 \n",
            " n,  x  =  14  6.000000 \n",
            " n,  x  =  15  7.000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "By going back to the previous code blocks you can modify the codes to complete the Practical 1 exercises.  Alternatively you can copy a Code cell (on my system I do this by using the mouse right-click) and paste it (control-V on my system) to form a new Code cell -- this is best for the final exercise in which you are to write a new code to add two vectors.\n",
        "\n",
        "However, this copy of the notebook is read-only for everyone except the owner (me!) so you will need to make your own copy of the notebook by going to the File option at the top and then clicking on \"Save a copy in Drive\" which will make a copy of it in your Google Drive.  You are then the owner of the copy and can edit it freely.\n",
        "\n",
        "For students doing this as an assignment to be assessed, you should add your name to the title of the notebook (as in \"Practical 1 -- Mike Giles.ipynb\"), make it shared (see the Share option in the top-right corner) and provide the shared link as the submission mechanism."
      ],
      "metadata": {
        "id": "ncymVLmd4L82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This final piece of code terminates the runtime for this notebook so that you can switch to a new notebook without any problems -- you will get an error message if you try to keep two runtimes going at the same time with the free Colab account.\n",
        "\n",
        "It's particularly convenient if you are executing the whole notebook to check everything works correctly, using the \"Run all\" option in the Runtime tab."
      ],
      "metadata": {
        "id": "qwBJXY68f9W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "XFPuNsfygVaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}