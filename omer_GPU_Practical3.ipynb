{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mamoro98/Cuda-Programming/blob/main/omer_GPU_Practical3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Omer Kamal Ali Ebead</h1>"
      ],
      "metadata": {
        "id": "tKxW999Rh1g-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CUDA Programming on NVIDIA GPUs, July 22-26, 2024**\n",
        "\n",
        "# **Practical 3**\n",
        "\n",
        "Again make sure the correct Runtime is being used, by clicking on the Runtime option at the top, then \"Change runtime type\", and selecting an appropriate GPU such as the T4.\n",
        "\n",
        "Then verify with the instruction below the details of the GPU which is available to you.  "
      ],
      "metadata": {
        "id": "i1JlUA_e44zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uboEpcMD4xYA",
        "outputId": "22a27955-6b73-4f4b-865f-170d63f950ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Feb 10 07:53:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "First we upload two header files from the course webpage."
      ],
      "metadata": {
        "id": "nlO6dHwW7gRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv1nyjTmTmr7",
        "outputId": "23a63a52-4398-48f5-e779-daebd94a102d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-10 07:53:29--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27832 (27K) [text/x-chdr]\n",
            "Saving to: ‘helper_cuda.h’\n",
            "\n",
            "helper_cuda.h       100%[===================>]  27.18K   158KB/s    in 0.2s    \n",
            "\n",
            "2025-02-10 07:53:30 (158 KB/s) - ‘helper_cuda.h’ saved [27832/27832]\n",
            "\n",
            "--2025-02-10 07:53:31--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14875 (15K) [text/x-chdr]\n",
            "Saving to: ‘helper_string.h’\n",
            "\n",
            "helper_string.h     100%[===================>]  14.53K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-10 07:53:31 (364 KB/s) - ‘helper_string.h’ saved [14875/14875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "The next step is to create the file laplace3d.cu which includes within it a reference C++ routine against which the CUDA results are compared."
      ],
      "metadata": {
        "id": "RD6IjBwY2Ltm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 16\n",
        "#define BLOCK_Y 16\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "                              const float* __restrict__ d_u1,\n",
        "                                    float* __restrict__ d_u2) // not allow to overlap\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  indg = i + j*NX;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  if ( i>=0 && i<=NX-1 && j>=0 && j<=NY-1 ) {\n",
        "\n",
        "    for (k=0; k<NZ; k++) {\n",
        "\n",
        "      if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "        u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "      }\n",
        "      else {\n",
        "        u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "             + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "             + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "      }\n",
        "      d_u2[indg] = u2;\n",
        "\n",
        "      indg += KOFF;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// same calc on cpu\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\t      ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=512, NY=512, NZ=512,\n",
        "            REPEAT=20, bx, by, i, j, k;\n",
        "  float    *h_u1, *h_u2, *h_foo,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // Gold treatment\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    Gold_laplace3d(NX, NY, NZ, h_u1, h_u2);\n",
        "    h_foo = h_u1; h_u1 = h_u2; h_u2 = h_foo;   // swap h_u1 and h_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx Gold_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "\n",
        "  // problem heeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeere !!\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "\n",
        "  dim3 dimGrid(bx,by);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  // if you want to check the error between the original array and the jacobia array\n",
        "  // checkCudaErrors( cudaMemcpy(h_u1, d_u2, bytes, cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %13f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcwQANS22i3Q",
        "outputId": "d26d4924-5927-4827-ddd9-c1b91334169f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting laplace3d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "We can now compile and run the executable.\n"
      ],
      "metadata": {
        "id": "yds03ug532rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d.cu -o laplace3d -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFHWm4Dd3_hw",
        "outputId": "d575e027-5a6d-4d3c-8101-06ba5e07bc2b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 64 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7jX9dSAaLj0",
        "outputId": "ca2097b8-a336-4254-b4d8-7bdcb841cab3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 512 x 512 x 512 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 115.1 (ms) \n",
            "\n",
            "20x Gold_laplace3d: 31890.0 (ms) \n",
            "\n",
            "20x GPU_laplace3d: 182.5 (ms) \n",
            "\n",
            "Copy u2 to host: 123.3 (ms) \n",
            "\n",
            "rms error =      0.000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "W1s-ISmB7zuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UDBqj2qU7y_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 16\n",
        "#define BLOCK_Y 16\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "                              const float* __restrict__ d_u1,\n",
        "                                    float* __restrict__ d_u2) // not allow to overlap\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  indg = i + j*NX;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  if ( i>=0 && i<=NX-1 && j>=0 && j<=NY-1 ) {\n",
        "\n",
        "    for (k=0; k<NZ; k++) {\n",
        "\n",
        "      if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "        u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "      }\n",
        "      else {\n",
        "        u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "             + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "             + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "      }\n",
        "      d_u2[indg] = u2;\n",
        "\n",
        "      indg += KOFF;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// same calc on cpu\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\t      ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024,\n",
        "            REPEAT=20, bx, by, i, j, k;\n",
        "  float    *h_u1, *h_u2,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // Gold treatment\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  // for (i=0; i<REPEAT; i++) {\n",
        "    // Gold_laplace3d(NX, NY, NZ, h_u1, h_u2);\n",
        "    // h_foo = h_u1; h_u1 = h_u2; h_u2 = h_foo;   // swap h_u1 and h_u2\n",
        "  // }\n",
        "\n",
        "  // cudaEventRecord(stop);\n",
        "  // cudaEventSynchronize(stop);\n",
        "  // cudaEventElapsedTime(&milli, start, stop);\n",
        "  // printf(\"%dx Gold_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "\n",
        "  // problem heeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeere !!\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "\n",
        "  dim3 dimGrid(bx,by);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  // if you want to check the error between the original array and the jacobia array\n",
        "  // checkCudaErrors( cudaMemcpy(h_u1, d_u2, bytes, cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  // float err = 0.0;\n",
        "\n",
        "  //for (k=0; k<NZ; k++) {\n",
        "  //  for (j=0; j<NY; j++) {\n",
        "  //    for (i=0; i<NX; i++) {\n",
        "  //      ind = i + j*NX + k*NX*NY;\n",
        "  //      err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "  //    }\n",
        "  //  }\n",
        "  // }\n",
        "\n",
        "  // printf(\"rms error = %13f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19361970-fb45-4e27-f3d8-3ae631859d9b",
        "id": "2Hq2nACx74Rv"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting laplace3d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d.cu -o laplace3d -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d695ed2-aca8-480c-c5a9-62567a077904",
        "id": "zfYeFWqJ74Rx"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 64 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c321ff5-85cd-43d2-ad4a-265e18eed06a",
        "id": "ynXLOXoN74Rx"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 942.4 (ms) \n",
            "\n",
            "20x GPU_laplace3d: 1956.0 (ms) \n",
            "\n",
            "Copy u2 to host: 3465.6 (ms) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8ROpjNg_7zCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5"
      ],
      "metadata": {
        "id": "KRTS8Z2_8_3_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d2D-Z_X17zGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 30\n",
        "#define BLOCK_Y 30\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "                              const float* __restrict__ d_u1,\n",
        "                                    float* __restrict__ d_u2) // not allow to overlap\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  indg = i + j*NX;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  if ( i>=0 && i<=NX-1 && j>=0 && j<=NY-1 ) {\n",
        "\n",
        "    for (k=0; k<NZ; k++) {\n",
        "\n",
        "      if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "        u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "      }\n",
        "      else {\n",
        "        u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "             + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "             + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "      }\n",
        "      d_u2[indg] = u2;\n",
        "\n",
        "      indg += KOFF;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// same calc on cpu\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\t      ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024,\n",
        "            REPEAT=20, bx, by, i, j, k;\n",
        "  float    *h_u1, *h_u2,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // Gold treatment\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  // for (i=0; i<REPEAT; i++) {\n",
        "    // Gold_laplace3d(NX, NY, NZ, h_u1, h_u2);\n",
        "    // h_foo = h_u1; h_u1 = h_u2; h_u2 = h_foo;   // swap h_u1 and h_u2\n",
        "  // }\n",
        "\n",
        "  // cudaEventRecord(stop);\n",
        "  // cudaEventSynchronize(stop);\n",
        "  // cudaEventElapsedTime(&milli, start, stop);\n",
        "  // printf(\"%dx Gold_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "\n",
        "  // problem heeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeere !!\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "\n",
        "  dim3 dimGrid(bx,by);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  // if you want to check the error between the original array and the jacobia array\n",
        "  // checkCudaErrors( cudaMemcpy(h_u1, d_u2, bytes, cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  // float err = 0.0;\n",
        "\n",
        "  //for (k=0; k<NZ; k++) {\n",
        "  //  for (j=0; j<NY; j++) {\n",
        "  //    for (i=0; i<NX; i++) {\n",
        "  //      ind = i + j*NX + k*NX*NY;\n",
        "  //      err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "  //    }\n",
        "  //  }\n",
        "  // }\n",
        "\n",
        "  // printf(\"rms error = %13f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7217cf59-4b24-4d65-e3f3-b9aeaac2220d",
        "id": "1jJCAqaZ9Ej1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting laplace3d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d.cu -o laplace3d -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486326ce-9735-4aa6-c6c1-8f086ef17a90",
        "id": "tomdmiem9Ej2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 64 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6db8e95-6bb1-44d8-e168-7fcf93339ce6",
        "id": "shWOddRD9Ej3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 935.1 (ms) \n",
            "\n",
            "20x GPU_laplace3d: 2371.8 (ms) \n",
            "\n",
            "Copy u2 to host: 3255.3 (ms) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16 * 16 = 1956\n",
        "\n",
        "30 * 30 = 2371\n",
        "\n",
        "31 * 31 = 2389\n",
        "\n",
        "32 * 32 = 1282"
      ],
      "metadata": {
        "id": "DJpUQMAc_L8s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2F4HZMtT9CJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3gn9X4it9CMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rD0NXUt99CPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B7CX0R7F9CSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o8ZmRx9d9CUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "By going back to the previous code block you can modify the code to complete the initial Practical 3 exercises. Remember to first make your own copy of the notebook so that you are able to edit it.\n",
        "\n",
        "For students doing this as an assignment to be assessed, you should again add your name to the title of the notebook (as in \"Practical 3 -- Mike Giles.ipynb\"), make it shared (see the Share option in the top-right corner) and provide the shared link as the submission mechanism.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "For the later parts of Practical 3, the instructions below create, compile and execute a second version of the code in which each CUDA thread computes the value for just one 3D grid point."
      ],
      "metadata": {
        "id": "ncymVLmd4L82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d_new.cu\n",
        "\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 16\n",
        "#define BLOCK_Y 4\n",
        "#define BLOCK_Z 4\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "\t         \t      const float* __restrict__ d_u1,\n",
        "\t\t\t            float* __restrict__ d_u2)\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  k    = threadIdx.z + blockIdx.z*BLOCK_Z;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  indg = i + j*JOFF + k*KOFF;\n",
        "\n",
        "  if (i>=0 && i<=NX-1 && j>=0 && j<=NY-1 && k>=0 && k<=NZ-1) {\n",
        "    if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "      u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "    }\n",
        "    else {\n",
        "      u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "           + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "           + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "    }\n",
        "    d_u2[indg] = u2;\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\tind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=512, NY=512, NZ=512,\n",
        "            REPEAT=1, bx, by, bz, i, j, k;\n",
        "  float    *h_u1, *h_u2, *h_foo,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // Gold treatment\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    Gold_laplace3d(NX, NY, NZ, h_u1, h_u2);\n",
        "    h_foo = h_u1; h_u1 = h_u2; h_u2 = h_foo;   // swap h_u1 and h_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx Gold_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "  bz = 1 + (NZ-1)/BLOCK_Z;\n",
        "\n",
        "  dim3 dimGrid(bx,by,bz);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y,BLOCK_Z);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d_new: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8xscLewbPlF",
        "outputId": "cc06ad7d-07ef-46a0-b026-80db20d99e74"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing laplace3d_new.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d_new.cu -o laplace3d_new -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzGXiohVT5OR",
        "outputId": "b422b4e9-8a1f-43a6-b727-51f9567c5d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 21 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsfyCekjazPh",
        "outputId": "c0d62b38-d368-47b5-9ab8-241475c8a12d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 512 x 512 x 512 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 127.6 (ms) \n",
            "\n",
            "20x Gold_laplace3d: 27956.3 (ms) \n",
            "\n",
            "20x GPU_laplace3d_new: 154.6 (ms) \n",
            "\n",
            "Copy u2 to host: 117.3 (ms) \n",
            "\n",
            "rms error = 0.000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "The next instructions check how many fp32 and integer instructions are performed by the two versions"
      ],
      "metadata": {
        "id": "8IUnwap2F64l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu --metrics \"smsp__sass_thread_inst_executed_op_fp32_pred_on.sum,smsp__sass_thread_inst_executed_op_integer_pred_on.sum\" ./laplace3d\n",
        "!ncu --metrics \"smsp__sass_thread_inst_executed_op_fp32_pred_on.sum,smsp__sass_thread_inst_executed_op_integer_pred_on.sum\" ./laplace3d_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kXdNtggGUv8",
        "outputId": "04bd09b6-66bc-425d-ba85-2df20f1cb94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 512 x 512 x 512 \n",
            "\n",
            "==PROF== Connected to process 5366 (/content/laplace3d)\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 126.8 (ms) \n",
            "\n",
            "20x Gold_laplace3d: 39791.3 (ms) \n",
            "\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 0: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 1: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 2: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 3: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 4: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 5: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 6: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 7: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 8: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 9: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 10: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 11: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 12: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 13: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 14: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 15: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 16: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 17: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 18: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 19: 0%....50%....100% - 1 pass\n",
            "20x GPU_laplace3d: 4682.6 (ms) \n",
            "\n",
            "Copy u2 to host: 121.7 (ms) \n",
            "\n",
            "rms error = 0.000000 \n",
            "==PROF== Disconnected from process 5366\n",
            "[5366] laplace3d@127.0.0.1\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 2,247,919,568\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "Grid dimensions: 512 x 512 x 512 \n",
            "\n",
            "==PROF== Connected to process 5620 (/content/laplace3d_new)\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 117.7 (ms) \n",
            "\n",
            "20x Gold_laplace3d: 39571.0 (ms) \n",
            "\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 0: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 1: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 2: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 3: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 4: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 5: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 6: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 7: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 8: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 9: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 10: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 11: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 12: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 13: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 14: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 15: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 16: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 17: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 18: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 19: 0%....50%....100% - 1 pass\n",
            "20x GPU_laplace3d_new: 10088.6 (ms) \n",
            "\n",
            "Copy u2 to host: 113.9 (ms) \n",
            "\n",
            "rms error = 0.000000 \n",
            "==PROF== Disconnected from process 5620\n",
            "[5620] laplace3d_new@127.0.0.1\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    Metric Name                                            Metric Unit  Metric Value\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst   795,906,000\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 8,296,431,488\n",
            "    ------------------------------------------------------ ----------- -------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUuh0SdITB-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu ./laplace3d\n",
        "!ncu ./laplace3d_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774450b5-7c4d-4442-c99b-f00eaf73309a",
        "id": "1USbXCV4TCpc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 512 x 512 x 512 \n",
            "\n",
            "==PROF== Connected to process 1243 (/content/laplace3d)\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 125.6 (ms) \n",
            "\n",
            "20x Gold_laplace3d: 42174.2 (ms) \n",
            "\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 0: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 1: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 2: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 3: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 4: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 5: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 6: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 7: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 8: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 9: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 10: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 11: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 12: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 13: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 14: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 15: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 16: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 17: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 18: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 19: 0%....50%....100% - 9 passes\n",
            "20x GPU_laplace3d: 5856.0 (ms) \n",
            "\n",
            "Copy u2 to host: 134.2 (ms) \n",
            "\n",
            "rms error = 0.000000 \n",
            "==PROF== Disconnected from process 1243\n",
            "[1243] laplace3d@127.0.0.1\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.98\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,339,721\n",
            "    Memory Throughput                 %        73.49\n",
            "    DRAM Throughput                   %        73.49\n",
            "    Duration                         ms         9.13\n",
            "    L1/TEX Cache Throughput           %        68.81\n",
            "    L2 Cache Throughput               %        24.10\n",
            "    SM Active Cycles              cycle 5,287,422.85\n",
            "    Compute (SM) Throughput           %        30.73\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        96.22\n",
            "    Achieved Active Warps Per SM           warp        30.79\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,413,859.50\n",
            "    Total DRAM Elapsed Cycles        cycle   363,737,088\n",
            "    Average L1 Active Cycles         cycle  5,287,422.85\n",
            "    Total L1 Elapsed Cycles          cycle   212,152,976\n",
            "    Average L2 Active Cycles         cycle  7,672,744.09\n",
            "    Total L2 Elapsed Cycles          cycle   246,027,744\n",
            "    Average SM Active Cycles         cycle  5,287,422.85\n",
            "    Total SM Elapsed Cycles          cycle   212,152,976\n",
            "    Average SMSP Active Cycles       cycle  5,293,712.56\n",
            "    Total SMSP Elapsed Cycles        cycle   848,611,904\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.05\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,296,904\n",
            "    Memory Throughput                 %        72.45\n",
            "    DRAM Throughput                   %        72.45\n",
            "    Duration                         ms         9.05\n",
            "    L1/TEX Cache Throughput           %        67.98\n",
            "    L2 Cache Throughput               %        24.30\n",
            "    SM Active Cycles              cycle 5,254,257.97\n",
            "    Compute (SM) Throughput           %        30.36\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.81\n",
            "    Achieved Active Warps Per SM           warp        30.66\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,112,947.50\n",
            "    Total DRAM Elapsed Cycles        cycle   365,613,056\n",
            "    Average L1 Active Cycles         cycle  5,254,257.97\n",
            "    Total L1 Elapsed Cycles          cycle   214,741,848\n",
            "    Average L2 Active Cycles         cycle  7,768,140.69\n",
            "    Total L2 Elapsed Cycles          cycle   244,337,024\n",
            "    Average SM Active Cycles         cycle  5,254,257.97\n",
            "    Total SM Elapsed Cycles          cycle   214,741,848\n",
            "    Average SMSP Active Cycles       cycle  5,270,377.42\n",
            "    Total SMSP Elapsed Cycles        cycle   858,967,392\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.93\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,416,915\n",
            "    Memory Throughput                 %        74.03\n",
            "    DRAM Throughput                   %        74.03\n",
            "    Duration                         ms         9.26\n",
            "    L1/TEX Cache Throughput           %        68.88\n",
            "    L2 Cache Throughput               %        23.75\n",
            "    SM Active Cycles              cycle 5,360,521.92\n",
            "    Compute (SM) Throughput           %        30.74\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        96.28\n",
            "    Achieved Active Warps Per SM           warp        30.81\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,783,510\n",
            "    Total DRAM Elapsed Cycles        cycle  365,064,192\n",
            "    Average L1 Active Cycles         cycle 5,360,521.92\n",
            "    Total L1 Elapsed Cycles          cycle  212,065,296\n",
            "    Average L2 Active Cycles         cycle 7,634,068.44\n",
            "    Total L2 Elapsed Cycles          cycle  250,108,512\n",
            "    Average SM Active Cycles         cycle 5,360,521.92\n",
            "    Total SM Elapsed Cycles          cycle  212,065,296\n",
            "    Average SMSP Active Cycles       cycle 5,318,922.68\n",
            "    Total SMSP Elapsed Cycles        cycle  848,261,184\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.03\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,289,575\n",
            "    Memory Throughput                 %        72.69\n",
            "    DRAM Throughput                   %        72.69\n",
            "    Duration                         ms         9.04\n",
            "    L1/TEX Cache Throughput           %        68.03\n",
            "    L2 Cache Throughput               %        24.50\n",
            "    SM Active Cycles              cycle    5,295,945\n",
            "    Compute (SM) Throughput           %        30.37\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.00\n",
            "    Achieved Active Warps Per SM           warp        30.40\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,041,143\n",
            "    Total DRAM Elapsed Cycles        cycle  363,659,264\n",
            "    Average L1 Active Cycles         cycle    5,295,945\n",
            "    Total L1 Elapsed Cycles          cycle  214,642,480\n",
            "    Average L2 Active Cycles         cycle 7,793,245.97\n",
            "    Total L2 Elapsed Cycles          cycle  244,075,360\n",
            "    Average SM Active Cycles         cycle    5,295,945\n",
            "    Total SM Elapsed Cycles          cycle  214,642,480\n",
            "    Average SMSP Active Cycles       cycle 5,345,040.61\n",
            "    Total SMSP Elapsed Cycles        cycle  858,569,920\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.07\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,274,048\n",
            "    Memory Throughput                 %        72.01\n",
            "    DRAM Throughput                   %        72.01\n",
            "    Duration                         ms         9.02\n",
            "    L1/TEX Cache Throughput           %        68.59\n",
            "    L2 Cache Throughput               %        24.56\n",
            "    SM Active Cycles              cycle 5,289,703.25\n",
            "    Compute (SM) Throughput           %        30.65\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        94.88\n",
            "    Achieved Active Warps Per SM           warp        30.36\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 32,884,448.50\n",
            "    Total DRAM Elapsed Cycles        cycle   365,309,952\n",
            "    Average L1 Active Cycles         cycle  5,289,703.25\n",
            "    Total L1 Elapsed Cycles          cycle   212,718,376\n",
            "    Average L2 Active Cycles         cycle  7,735,978.41\n",
            "    Total L2 Elapsed Cycles          cycle   243,575,616\n",
            "    Average SM Active Cycles         cycle  5,289,703.25\n",
            "    Total SM Elapsed Cycles          cycle   212,718,376\n",
            "    Average SMSP Active Cycles       cycle     5,269,052\n",
            "    Total SMSP Elapsed Cycles        cycle   850,873,504\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.04\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,285,250\n",
            "    Memory Throughput                 %        72.43\n",
            "    DRAM Throughput                   %        72.43\n",
            "    Duration                         ms         9.03\n",
            "    L1/TEX Cache Throughput           %        68.27\n",
            "    L2 Cache Throughput               %        24.40\n",
            "    SM Active Cycles              cycle 5,273,187.20\n",
            "    Compute (SM) Throughput           %        30.48\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.43\n",
            "    Achieved Active Warps Per SM           warp        30.54\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 32,989,332.50\n",
            "    Total DRAM Elapsed Cycles        cycle   364,385,280\n",
            "    Average L1 Active Cycles         cycle  5,273,187.20\n",
            "    Total L1 Elapsed Cycles          cycle   213,864,576\n",
            "    Average L2 Active Cycles         cycle  7,572,880.41\n",
            "    Total L2 Elapsed Cycles          cycle   244,366,112\n",
            "    Average SM Active Cycles         cycle  5,273,187.20\n",
            "    Total SM Elapsed Cycles          cycle   213,864,576\n",
            "    Average SMSP Active Cycles       cycle  5,316,847.73\n",
            "    Total SMSP Elapsed Cycles        cycle   855,458,304\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.07\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,297,572\n",
            "    Memory Throughput                 %        72.26\n",
            "    DRAM Throughput                   %        72.26\n",
            "    Duration                         ms         9.06\n",
            "    L1/TEX Cache Throughput           %        68.63\n",
            "    L2 Cache Throughput               %        24.38\n",
            "    SM Active Cycles              cycle 5,254,042.03\n",
            "    Compute (SM) Throughput           %        30.63\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        96.10\n",
            "    Achieved Active Warps Per SM           warp        30.75\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,193,585\n",
            "    Total DRAM Elapsed Cycles        cycle  367,501,312\n",
            "    Average L1 Active Cycles         cycle 5,254,042.03\n",
            "    Total L1 Elapsed Cycles          cycle  212,795,048\n",
            "    Average L2 Active Cycles         cycle 7,778,169.25\n",
            "    Total L2 Elapsed Cycles          cycle  244,176,512\n",
            "    Average SM Active Cycles         cycle 5,254,042.03\n",
            "    Total SM Elapsed Cycles          cycle  212,795,048\n",
            "    Average SMSP Active Cycles       cycle 5,286,758.91\n",
            "    Total SMSP Elapsed Cycles        cycle  851,180,192\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.03\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,301,770\n",
            "    Memory Throughput                 %        72.43\n",
            "    DRAM Throughput                   %        72.43\n",
            "    Duration                         ms         9.06\n",
            "    L1/TEX Cache Throughput           %        68.37\n",
            "    L2 Cache Throughput               %        24.42\n",
            "    SM Active Cycles              cycle 5,366,325.33\n",
            "    Compute (SM) Throughput           %        30.50\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        94.08\n",
            "    Achieved Active Warps Per SM           warp        30.11\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,045,967.50\n",
            "    Total DRAM Elapsed Cycles        cycle   364,986,368\n",
            "    Average L1 Active Cycles         cycle  5,366,325.33\n",
            "    Total L1 Elapsed Cycles          cycle   213,763,488\n",
            "    Average L2 Active Cycles         cycle  7,597,530.06\n",
            "    Total L2 Elapsed Cycles          cycle   245,209,632\n",
            "    Average SM Active Cycles         cycle  5,366,325.33\n",
            "    Total SM Elapsed Cycles          cycle   213,763,488\n",
            "    Average SMSP Active Cycles       cycle  5,297,576.11\n",
            "    Total SMSP Elapsed Cycles        cycle   855,053,952\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.02\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,298,895\n",
            "    Memory Throughput                 %        72.72\n",
            "    DRAM Throughput                   %        72.72\n",
            "    Duration                         ms         9.06\n",
            "    L1/TEX Cache Throughput           %        69.21\n",
            "    L2 Cache Throughput               %        24.34\n",
            "    SM Active Cycles              cycle 5,389,433.97\n",
            "    Compute (SM) Throughput           %        30.88\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        93.56\n",
            "    Achieved Active Warps Per SM           warp        29.94\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,087,178.50\n",
            "    Total DRAM Elapsed Cycles        cycle   363,982,848\n",
            "    Average L1 Active Cycles         cycle  5,389,433.97\n",
            "    Total L1 Elapsed Cycles          cycle   211,101,864\n",
            "    Average L2 Active Cycles         cycle  7,615,304.84\n",
            "    Total L2 Elapsed Cycles          cycle   244,437,024\n",
            "    Average SM Active Cycles         cycle  5,389,433.97\n",
            "    Total SM Elapsed Cycles          cycle   211,101,864\n",
            "    Average SMSP Active Cycles       cycle  5,252,808.16\n",
            "    Total SMSP Elapsed Cycles        cycle   844,407,456\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.98\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,350,206\n",
            "    Memory Throughput                 %        73.65\n",
            "    DRAM Throughput                   %        73.65\n",
            "    Duration                         ms         9.15\n",
            "    L1/TEX Cache Throughput           %        68.04\n",
            "    L2 Cache Throughput               %        24.06\n",
            "    SM Active Cycles              cycle 5,286,744.45\n",
            "    Compute (SM) Throughput           %        30.39\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        96.44\n",
            "    Achieved Active Warps Per SM           warp        30.86\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,550,032.50\n",
            "    Total DRAM Elapsed Cycles        cycle   364,449,792\n",
            "    Average L1 Active Cycles         cycle  5,286,744.45\n",
            "    Total L1 Elapsed Cycles          cycle   214,504,896\n",
            "    Average L2 Active Cycles         cycle  7,712,150.09\n",
            "    Total L2 Elapsed Cycles          cycle   247,086,976\n",
            "    Average SM Active Cycles         cycle  5,286,744.45\n",
            "    Total SM Elapsed Cycles          cycle   214,504,896\n",
            "    Average SMSP Active Cycles       cycle  5,352,329.71\n",
            "    Total SMSP Elapsed Cycles        cycle   858,019,584\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.98\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,321,515\n",
            "    Memory Throughput                 %        73.67\n",
            "    DRAM Throughput                   %        73.67\n",
            "    Duration                         ms         9.10\n",
            "    L1/TEX Cache Throughput           %        68.23\n",
            "    L2 Cache Throughput               %        24.20\n",
            "    SM Active Cycles              cycle 5,169,515.35\n",
            "    Compute (SM) Throughput           %        30.43\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        98.18\n",
            "    Achieved Active Warps Per SM           warp        31.42\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,339,255.50\n",
            "    Total DRAM Elapsed Cycles        cycle   362,057,728\n",
            "    Average L1 Active Cycles         cycle  5,169,515.35\n",
            "    Total L1 Elapsed Cycles          cycle   214,237,512\n",
            "    Average L2 Active Cycles         cycle     7,651,342\n",
            "    Total L2 Elapsed Cycles          cycle   245,788,256\n",
            "    Average SM Active Cycles         cycle  5,169,515.35\n",
            "    Total SM Elapsed Cycles          cycle   214,237,512\n",
            "    Average SMSP Active Cycles       cycle  5,315,726.93\n",
            "    Total SMSP Elapsed Cycles        cycle   856,950,048\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.98\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,375,349\n",
            "    Memory Throughput                 %        73.39\n",
            "    DRAM Throughput                   %        73.39\n",
            "    Duration                         ms         9.19\n",
            "    L1/TEX Cache Throughput           %        68.11\n",
            "    L2 Cache Throughput               %        24.00\n",
            "    SM Active Cycles              cycle 5,370,057.78\n",
            "    Compute (SM) Throughput           %        30.39\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.26\n",
            "    Achieved Active Warps Per SM           warp        30.48\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,573,957.50\n",
            "    Total DRAM Elapsed Cycles        cycle   365,961,216\n",
            "    Average L1 Active Cycles         cycle  5,370,057.78\n",
            "    Total L1 Elapsed Cycles          cycle   214,486,328\n",
            "    Average L2 Active Cycles         cycle  7,819,772.38\n",
            "    Total L2 Elapsed Cycles          cycle   248,214,528\n",
            "    Average SM Active Cycles         cycle  5,370,057.78\n",
            "    Total SM Elapsed Cycles          cycle   214,486,328\n",
            "    Average SMSP Active Cycles       cycle  5,326,582.36\n",
            "    Total SMSP Elapsed Cycles        cycle   857,945,312\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.11\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,221,062\n",
            "    Memory Throughput                 %        71.56\n",
            "    DRAM Throughput                   %        71.56\n",
            "    Duration                         ms         8.92\n",
            "    L1/TEX Cache Throughput           %        68.64\n",
            "    L2 Cache Throughput               %        24.82\n",
            "    SM Active Cycles              cycle 5,295,980.45\n",
            "    Compute (SM) Throughput           %        30.65\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        93.96\n",
            "    Achieved Active Warps Per SM           warp        30.07\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 32,648,223.50\n",
            "    Total DRAM Elapsed Cycles        cycle   365,010,944\n",
            "    Average L1 Active Cycles         cycle  5,295,980.45\n",
            "    Total L1 Elapsed Cycles          cycle   212,701,224\n",
            "    Average L2 Active Cycles         cycle  7,617,957.88\n",
            "    Total L2 Elapsed Cycles          cycle   241,054,400\n",
            "    Average SM Active Cycles         cycle  5,295,980.45\n",
            "    Total SM Elapsed Cycles          cycle   212,701,224\n",
            "    Average SMSP Active Cycles       cycle  5,261,744.67\n",
            "    Total SMSP Elapsed Cycles        cycle   850,804,896\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.05\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,357,457\n",
            "    Memory Throughput                 %        72.01\n",
            "    DRAM Throughput                   %        72.01\n",
            "    Duration                         ms         9.16\n",
            "    L1/TEX Cache Throughput           %        68.32\n",
            "    L2 Cache Throughput               %        23.94\n",
            "    SM Active Cycles              cycle 5,316,113.47\n",
            "    Compute (SM) Throughput           %        30.48\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.72\n",
            "    Achieved Active Warps Per SM           warp        30.63\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,287,175.50\n",
            "    Total DRAM Elapsed Cycles        cycle   369,786,880\n",
            "    Average L1 Active Cycles         cycle  5,316,113.47\n",
            "    Total L1 Elapsed Cycles          cycle   213,841,192\n",
            "    Average L2 Active Cycles         cycle  7,750,400.16\n",
            "    Total L2 Elapsed Cycles          cycle   247,359,200\n",
            "    Average SM Active Cycles         cycle  5,316,113.47\n",
            "    Total SM Elapsed Cycles          cycle   213,841,192\n",
            "    Average SMSP Active Cycles       cycle  5,314,775.07\n",
            "    Total SMSP Elapsed Cycles        cycle   855,364,768\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.94\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,329,200\n",
            "    Memory Throughput                 %        74.12\n",
            "    DRAM Throughput                   %        74.12\n",
            "    Duration                         ms         9.11\n",
            "    L1/TEX Cache Throughput           %        68.95\n",
            "    L2 Cache Throughput               %        24.29\n",
            "    SM Active Cycles              cycle 5,199,077.30\n",
            "    Compute (SM) Throughput           %        30.77\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        97.73\n",
            "    Achieved Active Warps Per SM           warp        31.27\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,376,446.50\n",
            "    Total DRAM Elapsed Cycles        cycle   360,239,104\n",
            "    Average L1 Active Cycles         cycle  5,199,077.30\n",
            "    Total L1 Elapsed Cycles          cycle   211,888,424\n",
            "    Average L2 Active Cycles         cycle  7,698,460.84\n",
            "    Total L2 Elapsed Cycles          cycle   245,674,304\n",
            "    Average SM Active Cycles         cycle  5,199,077.30\n",
            "    Total SM Elapsed Cycles          cycle   211,888,424\n",
            "    Average SMSP Active Cycles       cycle  5,269,402.98\n",
            "    Total SMSP Elapsed Cycles        cycle   847,553,696\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.05\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,269,548\n",
            "    Memory Throughput                 %        72.55\n",
            "    DRAM Throughput                   %        72.55\n",
            "    Duration                         ms         9.01\n",
            "    L1/TEX Cache Throughput           %        67.92\n",
            "    L2 Cache Throughput               %        24.63\n",
            "    SM Active Cycles              cycle 5,330,482.05\n",
            "    Compute (SM) Throughput           %        30.33\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        94.26\n",
            "    Achieved Active Warps Per SM           warp        30.16\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,024,749\n",
            "    Total DRAM Elapsed Cycles        cycle  364,154,880\n",
            "    Average L1 Active Cycles         cycle 5,330,482.05\n",
            "    Total L1 Elapsed Cycles          cycle  214,919,816\n",
            "    Average L2 Active Cycles         cycle 7,696,465.25\n",
            "    Total L2 Elapsed Cycles          cycle  243,039,040\n",
            "    Average SM Active Cycles         cycle 5,330,482.05\n",
            "    Total SM Elapsed Cycles          cycle  214,919,816\n",
            "    Average SMSP Active Cycles       cycle 5,282,277.83\n",
            "    Total SMSP Elapsed Cycles        cycle  859,679,264\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.94\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,333,094\n",
            "    Memory Throughput                 %        74.08\n",
            "    DRAM Throughput                   %        74.08\n",
            "    Duration                         ms         9.12\n",
            "    L1/TEX Cache Throughput           %        68.35\n",
            "    L2 Cache Throughput               %        24.31\n",
            "    SM Active Cycles              cycle 5,300,029.35\n",
            "    Compute (SM) Throughput           %        30.49\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.56\n",
            "    Achieved Active Warps Per SM           warp        30.58\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,364,202.50\n",
            "    Total DRAM Elapsed Cycles        cycle   360,321,024\n",
            "    Average L1 Active Cycles         cycle  5,300,029.35\n",
            "    Total L1 Elapsed Cycles          cycle   213,769,360\n",
            "    Average L2 Active Cycles         cycle  7,733,306.69\n",
            "    Total L2 Elapsed Cycles          cycle   246,640,192\n",
            "    Average SM Active Cycles         cycle  5,300,029.35\n",
            "    Total SM Elapsed Cycles          cycle   213,769,360\n",
            "    Average SMSP Active Cycles       cycle  5,249,719.73\n",
            "    Total SMSP Elapsed Cycles        cycle   855,077,440\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.05\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,345,374\n",
            "    Memory Throughput                 %        72.21\n",
            "    DRAM Throughput                   %        72.21\n",
            "    Duration                         ms         9.14\n",
            "    L1/TEX Cache Throughput           %        67.19\n",
            "    L2 Cache Throughput               %        24.11\n",
            "    SM Active Cycles              cycle 5,240,014.47\n",
            "    Compute (SM) Throughput           %        29.96\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        97.13\n",
            "    Achieved Active Warps Per SM           warp        31.08\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,352,426.50\n",
            "    Total DRAM Elapsed Cycles        cycle   369,490,944\n",
            "    Average L1 Active Cycles         cycle  5,240,014.47\n",
            "    Total L1 Elapsed Cycles          cycle   217,563,408\n",
            "    Average L2 Active Cycles         cycle  7,625,935.22\n",
            "    Total L2 Elapsed Cycles          cycle   246,504,064\n",
            "    Average SM Active Cycles         cycle  5,240,014.47\n",
            "    Total SM Elapsed Cycles          cycle   217,563,408\n",
            "    Average SMSP Active Cycles       cycle  5,366,078.13\n",
            "    Total SMSP Elapsed Cycles        cycle   870,253,632\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.93\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,378,754\n",
            "    Memory Throughput                 %        74.01\n",
            "    DRAM Throughput                   %        74.01\n",
            "    Duration                         ms         9.19\n",
            "    L1/TEX Cache Throughput           %        69.05\n",
            "    L2 Cache Throughput               %        24.03\n",
            "    SM Active Cycles              cycle 5,291,943.38\n",
            "    Compute (SM) Throughput           %        30.80\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        96.85\n",
            "    Achieved Active Warps Per SM           warp        30.99\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,580,835\n",
            "    Total DRAM Elapsed Cycles        cycle  362,987,520\n",
            "    Average L1 Active Cycles         cycle 5,291,943.38\n",
            "    Total L1 Elapsed Cycles          cycle  211,676,056\n",
            "    Average L2 Active Cycles         cycle 7,700,961.75\n",
            "    Total L2 Elapsed Cycles          cycle  248,261,728\n",
            "    Average SM Active Cycles         cycle 5,291,943.38\n",
            "    Total SM Elapsed Cycles          cycle  211,676,056\n",
            "    Average SMSP Active Cycles       cycle 5,305,733.69\n",
            "    Total SMSP Elapsed Cycles        cycle  846,704,224\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.02\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,364,458\n",
            "    Memory Throughput                 %        72.77\n",
            "    DRAM Throughput                   %        72.77\n",
            "    Duration                         ms         9.17\n",
            "    L1/TEX Cache Throughput           %        68.90\n",
            "    L2 Cache Throughput               %        24.03\n",
            "    SM Active Cycles              cycle 5,318,653.58\n",
            "    Compute (SM) Throughput           %        30.73\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.89\n",
            "    Achieved Active Warps Per SM           warp        30.69\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,492,053.50\n",
            "    Total DRAM Elapsed Cycles        cycle   368,177,152\n",
            "    Average L1 Active Cycles         cycle  5,318,653.58\n",
            "    Total L1 Elapsed Cycles          cycle   212,131,664\n",
            "    Average L2 Active Cycles         cycle  7,559,268.50\n",
            "    Total L2 Elapsed Cycles          cycle   247,778,080\n",
            "    Average SM Active Cycles         cycle  5,318,653.58\n",
            "    Total SM Elapsed Cycles          cycle   212,131,664\n",
            "    Average SMSP Active Cycles       cycle  5,286,529.53\n",
            "    Total SMSP Elapsed Cycles        cycle   848,526,656\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "Grid dimensions: 512 x 512 x 512 \n",
            "\n",
            "==PROF== Connected to process 1679 (/content/laplace3d_new)\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 122.2 (ms) \n",
            "\n",
            "20x Gold_laplace3d: 42221.6 (ms) \n",
            "\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 0: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 1: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 2: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 3: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 4: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 5: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 6: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 7: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 8: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 9: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 10: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 11: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 12: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 13: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 14: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 15: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 16: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 17: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 18: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 19: 0%....50%....100% - 9 passes\n",
            "20x GPU_laplace3d_new: 5685.5 (ms) \n",
            "\n",
            "Copy u2 to host: 128.8 (ms) \n",
            "\n",
            "rms error = 0.000000 \n",
            "==PROF== Disconnected from process 1679\n",
            "[1679] laplace3d_new@127.0.0.1\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,523,538\n",
            "    Memory Throughput                 %        68.06\n",
            "    DRAM Throughput                   %        68.06\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        89.04\n",
            "    L2 Cache Throughput               %        31.76\n",
            "    SM Active Cycles              cycle 4,521,168.40\n",
            "    Compute (SM) Throughput           %        51.61\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        83.59\n",
            "    Achieved Active Warps Per SM           warp        26.75\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 16.41%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.6%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   26,304,690\n",
            "    Total DRAM Elapsed Cycles        cycle  309,178,368\n",
            "    Average L1 Active Cycles         cycle 4,521,168.40\n",
            "    Total L1 Elapsed Cycles          cycle  180,891,296\n",
            "    Average L2 Active Cycles         cycle 6,507,546.72\n",
            "    Total L2 Elapsed Cycles          cycle  208,211,328\n",
            "    Average SM Active Cycles         cycle 4,521,168.40\n",
            "    Total SM Elapsed Cycles          cycle  180,891,296\n",
            "    Average SMSP Active Cycles       cycle 4,521,837.66\n",
            "    Total SMSP Elapsed Cycles        cycle  723,565,184\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.99\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,525,428\n",
            "    Memory Throughput                 %        68.15\n",
            "    DRAM Throughput                   %        68.15\n",
            "    Duration                         ms         7.74\n",
            "    L1/TEX Cache Throughput           %        89.01\n",
            "    L2 Cache Throughput               %        31.76\n",
            "    SM Active Cycles              cycle 4,522,495.55\n",
            "    Compute (SM) Throughput           %        51.59\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        83.59\n",
            "    Achieved Active Warps Per SM           warp        26.75\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 16.41%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.6%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,323,146.50\n",
            "    Total DRAM Elapsed Cycles        cycle   309,022,720\n",
            "    Average L1 Active Cycles         cycle  4,522,495.55\n",
            "    Total L1 Elapsed Cycles          cycle   180,962,112\n",
            "    Average L2 Active Cycles         cycle  6,501,711.66\n",
            "    Total L2 Elapsed Cycles          cycle   208,327,648\n",
            "    Average SM Active Cycles         cycle  4,522,495.55\n",
            "    Total SM Elapsed Cycles          cycle   180,962,112\n",
            "    Average SMSP Active Cycles       cycle  4,522,141.92\n",
            "    Total SMSP Elapsed Cycles        cycle   723,848,448\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.99\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,524,033\n",
            "    Memory Throughput                 %        68.11\n",
            "    DRAM Throughput                   %        68.11\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        89.01\n",
            "    L2 Cache Throughput               %        31.77\n",
            "    SM Active Cycles              cycle 4,524,161.22\n",
            "    Compute (SM) Throughput           %        51.59\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        83.54\n",
            "    Achieved Active Warps Per SM           warp        26.73\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 16.46%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.5%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   26,299,171\n",
            "    Total DRAM Elapsed Cycles        cycle  308,908,032\n",
            "    Average L1 Active Cycles         cycle 4,524,161.22\n",
            "    Total L1 Elapsed Cycles          cycle  180,966,384\n",
            "    Average L2 Active Cycles         cycle 6,506,678.19\n",
            "    Total L2 Elapsed Cycles          cycle  208,166,080\n",
            "    Average SM Active Cycles         cycle 4,524,161.22\n",
            "    Total SM Elapsed Cycles          cycle  180,966,384\n",
            "    Average SMSP Active Cycles       cycle 4,525,303.99\n",
            "    Total SMSP Elapsed Cycles        cycle  723,865,536\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,524,571\n",
            "    Memory Throughput                 %        68.07\n",
            "    DRAM Throughput                   %        68.07\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        89.01\n",
            "    L2 Cache Throughput               %        31.78\n",
            "    SM Active Cycles              cycle 4,521,239.53\n",
            "    Compute (SM) Throughput           %        51.59\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        83.60\n",
            "    Achieved Active Warps Per SM           warp        26.75\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 16.4%                                                                                     \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.6%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,308,085.50\n",
            "    Total DRAM Elapsed Cycles        cycle   309,186,560\n",
            "    Average L1 Active Cycles         cycle  4,521,239.53\n",
            "    Total L1 Elapsed Cycles          cycle   180,945,904\n",
            "    Average L2 Active Cycles         cycle  6,506,560.59\n",
            "    Total L2 Elapsed Cycles          cycle   208,110,848\n",
            "    Average SM Active Cycles         cycle  4,521,239.53\n",
            "    Total SM Elapsed Cycles          cycle   180,945,904\n",
            "    Average SMSP Active Cycles       cycle  4,520,830.60\n",
            "    Total SMSP Elapsed Cycles        cycle   723,783,616\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,524,433\n",
            "    Memory Throughput                 %        68.10\n",
            "    DRAM Throughput                   %        68.10\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        89.06\n",
            "    L2 Cache Throughput               %        31.76\n",
            "    SM Active Cycles              cycle 4,524,812.17\n",
            "    Compute (SM) Throughput           %        51.62\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        83.53\n",
            "    Achieved Active Warps Per SM           warp        26.73\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 16.47%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.5%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,314,740.50\n",
            "    Total DRAM Elapsed Cycles        cycle   309,122,048\n",
            "    Average L1 Active Cycles         cycle  4,524,812.17\n",
            "    Total L1 Elapsed Cycles          cycle   180,868,544\n",
            "    Average L2 Active Cycles         cycle  6,507,225.81\n",
            "    Total L2 Elapsed Cycles          cycle   208,338,816\n",
            "    Average SM Active Cycles         cycle  4,524,812.17\n",
            "    Total SM Elapsed Cycles          cycle   180,868,544\n",
            "    Average SMSP Active Cycles       cycle  4,524,524.82\n",
            "    Total SMSP Elapsed Cycles        cycle   723,474,176\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.99\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,525,587\n",
            "    Memory Throughput                 %        68.09\n",
            "    DRAM Throughput                   %        68.09\n",
            "    Duration                         ms         7.74\n",
            "    L1/TEX Cache Throughput           %        88.25\n",
            "    L2 Cache Throughput               %        31.76\n",
            "    SM Active Cycles              cycle 4,556,647.10\n",
            "    Compute (SM) Throughput           %        51.17\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.97\n",
            "    Achieved Active Warps Per SM           warp        26.55\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.03%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.0%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,305,531.50\n",
            "    Total DRAM Elapsed Cycles        cycle   309,090,304\n",
            "    Average L1 Active Cycles         cycle  4,556,647.10\n",
            "    Total L1 Elapsed Cycles          cycle   182,443,288\n",
            "    Average L2 Active Cycles         cycle  6,390,750.59\n",
            "    Total L2 Elapsed Cycles          cycle   208,206,208\n",
            "    Average SM Active Cycles         cycle  4,556,647.10\n",
            "    Total SM Elapsed Cycles          cycle   182,443,288\n",
            "    Average SMSP Active Cycles       cycle  4,525,245.83\n",
            "    Total SMSP Elapsed Cycles        cycle   729,773,152\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,522,806\n",
            "    Memory Throughput                 %        68.12\n",
            "    DRAM Throughput                   %        68.12\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        88.32\n",
            "    L2 Cache Throughput               %        31.73\n",
            "    SM Active Cycles              cycle 4,558,106.47\n",
            "    Compute (SM) Throughput           %        51.21\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.88\n",
            "    Achieved Active Warps Per SM           warp        26.52\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.12%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   26,310,092\n",
            "    Total DRAM Elapsed Cycles        cycle  308,994,048\n",
            "    Average L1 Active Cycles         cycle 4,558,106.47\n",
            "    Total L1 Elapsed Cycles          cycle  182,314,216\n",
            "    Average L2 Active Cycles         cycle 6,392,693.84\n",
            "    Total L2 Elapsed Cycles          cycle  208,439,488\n",
            "    Average SM Active Cycles         cycle 4,558,106.47\n",
            "    Total SM Elapsed Cycles          cycle  182,314,216\n",
            "    Average SMSP Active Cycles       cycle 4,548,677.31\n",
            "    Total SMSP Elapsed Cycles        cycle  729,256,864\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.99\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,523,702\n",
            "    Memory Throughput                 %        68.13\n",
            "    DRAM Throughput                   %        68.13\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        88.32\n",
            "    L2 Cache Throughput               %        31.73\n",
            "    SM Active Cycles              cycle 4,556,501.60\n",
            "    Compute (SM) Throughput           %        51.21\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.93\n",
            "    Achieved Active Warps Per SM           warp        26.54\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.07%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,307,248.50\n",
            "    Total DRAM Elapsed Cycles        cycle   308,903,936\n",
            "    Average L1 Active Cycles         cycle  4,556,501.60\n",
            "    Total L1 Elapsed Cycles          cycle   182,305,736\n",
            "    Average L2 Active Cycles         cycle  6,394,100.28\n",
            "    Total L2 Elapsed Cycles          cycle   208,428,416\n",
            "    Average SM Active Cycles         cycle  4,556,501.60\n",
            "    Total SM Elapsed Cycles          cycle   182,305,736\n",
            "    Average SMSP Active Cycles       cycle  4,554,791.17\n",
            "    Total SMSP Elapsed Cycles        cycle   729,222,944\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,524,530\n",
            "    Memory Throughput                 %        68.08\n",
            "    DRAM Throughput                   %        68.08\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        88.29\n",
            "    L2 Cache Throughput               %        31.74\n",
            "    SM Active Cycles              cycle 4,557,236.58\n",
            "    Compute (SM) Throughput           %        51.19\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.94\n",
            "    Achieved Active Warps Per SM           warp        26.54\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.06%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,307,937.50\n",
            "    Total DRAM Elapsed Cycles        cycle   309,161,984\n",
            "    Average L1 Active Cycles         cycle  4,557,236.58\n",
            "    Total L1 Elapsed Cycles          cycle   182,379,272\n",
            "    Average L2 Active Cycles         cycle  6,393,787.25\n",
            "    Total L2 Elapsed Cycles          cycle   208,382,400\n",
            "    Average SM Active Cycles         cycle  4,557,236.58\n",
            "    Total SM Elapsed Cycles          cycle   182,379,272\n",
            "    Average SMSP Active Cycles       cycle  4,554,362.80\n",
            "    Total SMSP Elapsed Cycles        cycle   729,517,088\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,521,193\n",
            "    Memory Throughput                 %        68.10\n",
            "    DRAM Throughput                   %        68.10\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        88.31\n",
            "    L2 Cache Throughput               %        31.72\n",
            "    SM Active Cycles              cycle 4,559,457.53\n",
            "    Compute (SM) Throughput           %        51.20\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.83\n",
            "    Achieved Active Warps Per SM           warp        26.50\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.17%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   26,308,493\n",
            "    Total DRAM Elapsed Cycles        cycle  309,039,104\n",
            "    Average L1 Active Cycles         cycle 4,559,457.53\n",
            "    Total L1 Elapsed Cycles          cycle  182,335,328\n",
            "    Average L2 Active Cycles         cycle 6,388,649.09\n",
            "    Total L2 Elapsed Cycles          cycle  208,461,824\n",
            "    Average SM Active Cycles         cycle 4,559,457.53\n",
            "    Total SM Elapsed Cycles          cycle  182,335,328\n",
            "    Average SMSP Active Cycles       cycle 4,559,600.48\n",
            "    Total SMSP Elapsed Cycles        cycle  729,341,312\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.99\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,524,385\n",
            "    Memory Throughput                 %        68.10\n",
            "    DRAM Throughput                   %        68.10\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        88.33\n",
            "    L2 Cache Throughput               %        31.76\n",
            "    SM Active Cycles              cycle 4,556,990.58\n",
            "    Compute (SM) Throughput           %        51.21\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.94\n",
            "    Achieved Active Warps Per SM           warp        26.54\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.06%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,301,332.50\n",
            "    Total DRAM Elapsed Cycles        cycle   308,961,280\n",
            "    Average L1 Active Cycles         cycle  4,556,990.58\n",
            "    Total L1 Elapsed Cycles          cycle   182,288,560\n",
            "    Average L2 Active Cycles         cycle  6,398,975.06\n",
            "    Total L2 Elapsed Cycles          cycle   208,251,136\n",
            "    Average SM Active Cycles         cycle  4,556,990.58\n",
            "    Total SM Elapsed Cycles          cycle   182,288,560\n",
            "    Average SMSP Active Cycles       cycle  4,555,938.74\n",
            "    Total SMSP Elapsed Cycles        cycle   729,154,240\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,523,673\n",
            "    Memory Throughput                 %        68.08\n",
            "    DRAM Throughput                   %        68.08\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        88.31\n",
            "    L2 Cache Throughput               %        31.77\n",
            "    SM Active Cycles              cycle 4,555,937.80\n",
            "    Compute (SM) Throughput           %        51.20\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.95\n",
            "    Achieved Active Warps Per SM           warp        26.55\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.05%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.0%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   26,305,764\n",
            "    Total DRAM Elapsed Cycles        cycle  309,116,928\n",
            "    Average L1 Active Cycles         cycle 4,555,937.80\n",
            "    Total L1 Elapsed Cycles          cycle  182,339,120\n",
            "    Average L2 Active Cycles         cycle 6,396,588.72\n",
            "    Total L2 Elapsed Cycles          cycle  208,163,520\n",
            "    Average SM Active Cycles         cycle 4,555,937.80\n",
            "    Total SM Elapsed Cycles          cycle  182,339,120\n",
            "    Average SMSP Active Cycles       cycle 4,558,415.24\n",
            "    Total SMSP Elapsed Cycles        cycle  729,356,480\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.99\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,526,469\n",
            "    Memory Throughput                 %        68.11\n",
            "    DRAM Throughput                   %        68.11\n",
            "    Duration                         ms         7.74\n",
            "    L1/TEX Cache Throughput           %        88.28\n",
            "    L2 Cache Throughput               %        31.73\n",
            "    SM Active Cycles              cycle 4,556,733.80\n",
            "    Compute (SM) Throughput           %        51.18\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.98\n",
            "    Achieved Active Warps Per SM           warp        26.55\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.02%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.0%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,311,042.50\n",
            "    Total DRAM Elapsed Cycles        cycle   309,059,584\n",
            "    Average L1 Active Cycles         cycle  4,556,733.80\n",
            "    Total L1 Elapsed Cycles          cycle   182,390,680\n",
            "    Average L2 Active Cycles         cycle  6,393,152.59\n",
            "    Total L2 Elapsed Cycles          cycle   208,397,568\n",
            "    Average SM Active Cycles         cycle  4,556,733.80\n",
            "    Total SM Elapsed Cycles          cycle   182,390,680\n",
            "    Average SMSP Active Cycles       cycle  4,557,266.61\n",
            "    Total SMSP Elapsed Cycles        cycle   729,562,720\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.99\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,525,510\n",
            "    Memory Throughput                 %        68.09\n",
            "    DRAM Throughput                   %        68.09\n",
            "    Duration                         ms         7.74\n",
            "    L1/TEX Cache Throughput           %        88.28\n",
            "    L2 Cache Throughput               %        31.77\n",
            "    SM Active Cycles              cycle 4,556,905.28\n",
            "    Compute (SM) Throughput           %        51.19\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.96\n",
            "    Achieved Active Warps Per SM           warp        26.55\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.04%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.0%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   26,302,645\n",
            "    Total DRAM Elapsed Cycles        cycle  309,043,200\n",
            "    Average L1 Active Cycles         cycle 4,556,905.28\n",
            "    Total L1 Elapsed Cycles          cycle  182,387,456\n",
            "    Average L2 Active Cycles         cycle 6,388,109.38\n",
            "    Total L2 Elapsed Cycles          cycle  208,177,792\n",
            "    Average SM Active Cycles         cycle 4,556,905.28\n",
            "    Total SM Elapsed Cycles          cycle  182,387,456\n",
            "    Average SMSP Active Cycles       cycle 4,559,290.50\n",
            "    Total SMSP Elapsed Cycles        cycle  729,549,824\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,522,837\n",
            "    Memory Throughput                 %        68.10\n",
            "    DRAM Throughput                   %        68.10\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        88.26\n",
            "    L2 Cache Throughput               %        31.76\n",
            "    SM Active Cycles              cycle 4,558,764.72\n",
            "    Compute (SM) Throughput           %        51.17\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.88\n",
            "    Achieved Active Warps Per SM           warp        26.52\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.12%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,305,820.50\n",
            "    Total DRAM Elapsed Cycles        cycle   309,035,008\n",
            "    Average L1 Active Cycles         cycle  4,558,764.72\n",
            "    Total L1 Elapsed Cycles          cycle   182,444,312\n",
            "    Average L2 Active Cycles         cycle  6,393,957.25\n",
            "    Total L2 Elapsed Cycles          cycle   208,217,216\n",
            "    Average SM Active Cycles         cycle  4,558,764.72\n",
            "    Total SM Elapsed Cycles          cycle   182,444,312\n",
            "    Average SMSP Active Cycles       cycle  4,558,446.60\n",
            "    Total SMSP Elapsed Cycles        cycle   729,777,248\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.99\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,525,058\n",
            "    Memory Throughput                 %        68.09\n",
            "    DRAM Throughput                   %        68.09\n",
            "    Duration                         ms         7.74\n",
            "    L1/TEX Cache Throughput           %        88.31\n",
            "    L2 Cache Throughput               %        31.74\n",
            "    SM Active Cycles              cycle 4,558,073.85\n",
            "    Compute (SM) Throughput           %        51.20\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.92\n",
            "    Achieved Active Warps Per SM           warp        26.54\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.08%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,304,619.50\n",
            "    Total DRAM Elapsed Cycles        cycle   309,074,944\n",
            "    Average L1 Active Cycles         cycle  4,558,073.85\n",
            "    Total L1 Elapsed Cycles          cycle   182,321,496\n",
            "    Average L2 Active Cycles         cycle  6,381,882.25\n",
            "    Total L2 Elapsed Cycles          cycle   208,356,352\n",
            "    Average SM Active Cycles         cycle  4,558,073.85\n",
            "    Total SM Elapsed Cycles          cycle   182,321,496\n",
            "    Average SMSP Active Cycles       cycle  4,557,649.64\n",
            "    Total SMSP Elapsed Cycles        cycle   729,285,984\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,523,151\n",
            "    Memory Throughput                 %        68.05\n",
            "    DRAM Throughput                   %        68.05\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        88.31\n",
            "    L2 Cache Throughput               %        31.73\n",
            "    SM Active Cycles              cycle 4,555,833.72\n",
            "    Compute (SM) Throughput           %        51.20\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.94\n",
            "    Achieved Active Warps Per SM           warp        26.54\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.06%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,299,858.50\n",
            "    Total DRAM Elapsed Cycles        cycle   309,202,944\n",
            "    Average L1 Active Cycles         cycle  4,555,833.72\n",
            "    Total L1 Elapsed Cycles          cycle   182,319,984\n",
            "    Average L2 Active Cycles         cycle  6,398,428.66\n",
            "    Total L2 Elapsed Cycles          cycle   208,443,168\n",
            "    Average SM Active Cycles         cycle  4,555,833.72\n",
            "    Total SM Elapsed Cycles          cycle   182,319,984\n",
            "    Average SMSP Active Cycles       cycle  4,559,153.91\n",
            "    Total SMSP Elapsed Cycles        cycle   729,279,936\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,522,752\n",
            "    Memory Throughput                 %        68.10\n",
            "    DRAM Throughput                   %        68.10\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        88.29\n",
            "    L2 Cache Throughput               %        31.74\n",
            "    SM Active Cycles              cycle 4,555,742.08\n",
            "    Compute (SM) Throughput           %        51.19\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.93\n",
            "    Achieved Active Warps Per SM           warp        26.54\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.07%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   26,304,970\n",
            "    Total DRAM Elapsed Cycles        cycle  309,026,816\n",
            "    Average L1 Active Cycles         cycle 4,555,742.08\n",
            "    Total L1 Elapsed Cycles          cycle  182,374,440\n",
            "    Average L2 Active Cycles         cycle 6,390,944.72\n",
            "    Total L2 Elapsed Cycles          cycle  208,357,920\n",
            "    Average SM Active Cycles         cycle 4,555,742.08\n",
            "    Total SM Elapsed Cycles          cycle  182,374,440\n",
            "    Average SMSP Active Cycles       cycle 4,543,765.46\n",
            "    Total SMSP Elapsed Cycles        cycle  729,497,760\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,523,207\n",
            "    Memory Throughput                 %        68.11\n",
            "    DRAM Throughput                   %        68.11\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        88.31\n",
            "    L2 Cache Throughput               %        31.74\n",
            "    SM Active Cycles              cycle 4,555,326.45\n",
            "    Compute (SM) Throughput           %        51.20\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.95\n",
            "    Achieved Active Warps Per SM           warp        26.54\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.05%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 26,307,306.50\n",
            "    Total DRAM Elapsed Cycles        cycle   309,006,336\n",
            "    Average L1 Active Cycles         cycle  4,555,326.45\n",
            "    Total L1 Elapsed Cycles          cycle   182,321,704\n",
            "    Average L2 Active Cycles         cycle  6,391,173.84\n",
            "    Total L2 Elapsed Cycles          cycle   208,364,864\n",
            "    Average SM Active Cycles         cycle  4,555,326.45\n",
            "    Total SM Elapsed Cycles          cycle   182,321,704\n",
            "    Average SMSP Active Cycles       cycle  4,558,062.16\n",
            "    Total SMSP Elapsed Cycles        cycle   729,286,816\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 128, 128)x(16, 4, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    4,522,044\n",
            "    Memory Throughput                 %        68.09\n",
            "    DRAM Throughput                   %        68.09\n",
            "    Duration                         ms         7.73\n",
            "    L1/TEX Cache Throughput           %        88.29\n",
            "    L2 Cache Throughput               %        31.75\n",
            "    SM Active Cycles              cycle 4,556,799.95\n",
            "    Compute (SM) Throughput           %        51.19\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                524,288\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread     134,217,728\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                            3,276.80\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.89\n",
            "    Achieved Active Warps Per SM           warp        26.53\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.11%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   26,306,128\n",
            "    Total DRAM Elapsed Cycles        cycle  309,055,488\n",
            "    Average L1 Active Cycles         cycle 4,556,799.95\n",
            "    Total L1 Elapsed Cycles          cycle  182,380,400\n",
            "    Average L2 Active Cycles         cycle 6,391,903.47\n",
            "    Total L2 Elapsed Cycles          cycle  208,285,184\n",
            "    Average SM Active Cycles         cycle 4,556,799.95\n",
            "    Total SM Elapsed Cycles          cycle  182,380,400\n",
            "    Average SMSP Active Cycles       cycle 4,557,051.91\n",
            "    Total SMSP Elapsed Cycles        cycle  729,521,600\n",
            "    -------------------------- ----------- ------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "MtAImDxLjEpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}