{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mamoro98/Cuda-Programming/blob/main/Omer_Practical_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CUDA Programming on NVIDIA GPUs, July 22-26, 2024**\n",
        "\n",
        "# **Practical 1**\n",
        "\n",
        "First of all, make sure the correct Runtime is being used, by clicking on the Runtime option at the top, then \"Change runtime type\", selecting an appropriate GPU such as the T4, then clicking Save.\n",
        "\n",
        "A Colab Pro or Pro+ account will allow you to use a more powerful GPU, but the freely available T4 is perfectly adequate for the practicals in this course. It has good single precision capabilities and corresponds to Compute Capability 7.5.\n",
        "\n",
        "To check that this has been done successfully, the first instruction below returns information on the version of the available NVIDIA compiler, and the second instruction returns information on the GPU which is available to you.  \n",
        "\n",
        "To \"execute\" each cell, click on the little triangle to the left of the instructions.  The ! tells Colab that these are system commands to be executed."
      ],
      "metadata": {
        "id": "i1JlUA_e44zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uboEpcMD4xYA",
        "outputId": "a210e6c8-cf98-4cf0-ba69-99dc0820857f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnJ21Z177Tc2",
        "outputId": "5d196208-bfd8-48d9-be5f-9f81b407e712"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb  4 12:13:04 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "The first step is to upload two header files from the course webpage."
      ],
      "metadata": {
        "id": "nlO6dHwW7gRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv1nyjTmTmr7",
        "outputId": "f0cfe5f7-d374-4445-dc43-e502622a804d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-04 12:13:25--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27832 (27K) [text/x-chdr]\n",
            "Saving to: ‘helper_cuda.h’\n",
            "\n",
            "helper_cuda.h       100%[===================>]  27.18K   158KB/s    in 0.2s    \n",
            "\n",
            "2025-02-04 12:13:27 (158 KB/s) - ‘helper_cuda.h’ saved [27832/27832]\n",
            "\n",
            "--2025-02-04 12:13:27--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14875 (15K) [text/x-chdr]\n",
            "Saving to: ‘helper_string.h’\n",
            "\n",
            "helper_string.h     100%[===================>]  14.53K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-04 12:13:28 (374 KB/s) - ‘helper_string.h’ saved [14875/14875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "Next we create the file prac1a.cu by using the %%writefile instruction at the top of the code block.\n",
        "\n",
        "In doing this, we are following the helpful information provided here:\n",
        "https://colab.research.google.com/drive/1GJOfTp56OeQRdE4u2_S7pUNRcJb4ik9X?usp=sharing"
      ],
      "metadata": {
        "id": "FqvXt9br-gW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac1a.cu\n",
        "\n",
        "//\n",
        "// include files\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "//\n",
        "// kernel routine\n",
        "//\n",
        "\n",
        "__global__ void my_first_kernel(float *x)\n",
        "{\n",
        "  int tid = threadIdx.x + blockDim.x*blockIdx.x;\n",
        "\n",
        "  printf(\"tid = %i , thred index = %i , block idx = %i , block dim = %i \\n\",tid,threadIdx.x,blockIdx.x,blockDim.x);\n",
        "\n",
        "  x[tid] = (float) threadIdx.x;\n",
        "}\n",
        "\n",
        "\n",
        "//\n",
        "// main code\n",
        "//\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "  float *h_x, *d_x;\n",
        "  int   nblocks, nthreads, nsize, n;\n",
        "\n",
        "  // set number of blocks, and threads per block\n",
        "\n",
        "  nblocks  = 2;\n",
        "  nthreads = 8;\n",
        "  nsize    = nblocks*nthreads ;\n",
        "\n",
        "  // allocate memory for array\n",
        "\n",
        "  h_x = (float *)malloc(nsize*sizeof(float));\n",
        "  cudaMalloc((void **)&d_x, nsize*sizeof(float));\n",
        "\n",
        "  // execute kernel\n",
        "\n",
        "  my_first_kernel<<<nblocks,nthreads>>>(d_x);\n",
        "\n",
        "  // copy back results and print them out\n",
        "\n",
        "  cudaMemcpy(h_x,d_x,nsize*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\n",
        "  for (n=0; n<nsize; n++) printf(\" n,  x  =  %d  %f \\n\",n,h_x[n]);\n",
        "\n",
        "  // free memory\n",
        "\n",
        "  cudaFree(d_x);\n",
        "  free(h_x);\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcwQANS22i3Q",
        "outputId": "df8c2d58-6b55-496e-e63a-8109a9831470"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prac1a.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "We use the following instruction to compile prac1a.cu to create the executable output prac1a.  The other flags are as follows:\n",
        "\n",
        "-I. says to look in the current directory for header files\n",
        "\n",
        "-lineinfo helps with debugging if there's a run-time problem\n",
        "\n",
        "-arch=sm_70 says it is for GPUs of Compute Capability 7.0 or later\n",
        "\n",
        "--ptxas=-v gives us additional information such as how many registers are used\n",
        "\n",
        "--use_fast_math generates faster code which might sometimes be a little less accurate\n",
        "\n",
        "-lcudart links in the run-time CUDA library\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWTkuuk_arY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac1a.cu -o prac1a -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HObz_6vOa8P1",
        "outputId": "15e4115b-7373-4a24-8549-25b332637ce5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 64 bytes gmem, 16 bytes cmem[4]\n",
            "ptxas info    : Compiling entry function '_Z15my_first_kernelPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z15my_first_kernelPf\n",
            "    16 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 24 registers, 16 bytes cumulative stack size, 360 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Now we can execute the code.\n"
      ],
      "metadata": {
        "id": "Ku927eQ01g4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac1a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm0vvMosUm3C",
        "outputId": "b0ad50ae-9a79-4601-e8a6-8a3a127f5908"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tid = 8 , thred index = 0 , block idx = 1 , block dim = 8 \n",
            "tid = 9 , thred index = 1 , block idx = 1 , block dim = 8 \n",
            "tid = 10 , thred index = 2 , block idx = 1 , block dim = 8 \n",
            "tid = 11 , thred index = 3 , block idx = 1 , block dim = 8 \n",
            "tid = 12 , thred index = 4 , block idx = 1 , block dim = 8 \n",
            "tid = 13 , thred index = 5 , block idx = 1 , block dim = 8 \n",
            "tid = 14 , thred index = 6 , block idx = 1 , block dim = 8 \n",
            "tid = 15 , thred index = 7 , block idx = 1 , block dim = 8 \n",
            "tid = 0 , thred index = 0 , block idx = 0 , block dim = 8 \n",
            "tid = 1 , thred index = 1 , block idx = 0 , block dim = 8 \n",
            "tid = 2 , thred index = 2 , block idx = 0 , block dim = 8 \n",
            "tid = 3 , thred index = 3 , block idx = 0 , block dim = 8 \n",
            "tid = 4 , thred index = 4 , block idx = 0 , block dim = 8 \n",
            "tid = 5 , thred index = 5 , block idx = 0 , block dim = 8 \n",
            "tid = 6 , thred index = 6 , block idx = 0 , block dim = 8 \n",
            "tid = 7 , thred index = 7 , block idx = 0 , block dim = 8 \n",
            " n,  x  =  0  0.000000 \n",
            " n,  x  =  1  1.000000 \n",
            " n,  x  =  2  2.000000 \n",
            " n,  x  =  3  3.000000 \n",
            " n,  x  =  4  4.000000 \n",
            " n,  x  =  5  5.000000 \n",
            " n,  x  =  6  6.000000 \n",
            " n,  x  =  7  7.000000 \n",
            " n,  x  =  8  0.000000 \n",
            " n,  x  =  9  1.000000 \n",
            " n,  x  =  10  2.000000 \n",
            " n,  x  =  11  3.000000 \n",
            " n,  x  =  12  4.000000 \n",
            " n,  x  =  13  5.000000 \n",
            " n,  x  =  14  6.000000 \n",
            " n,  x  =  15  7.000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "We can now perform the same steps for the second code, prac1b.cu, which does lots of error-checking."
      ],
      "metadata": {
        "id": "yds03ug532rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac1b.cu\n",
        "\n",
        "//\n",
        "// include files\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "\n",
        "//\n",
        "// kernel routine\n",
        "//\n",
        "\n",
        "__global__ void my_first_kernel(float *x)\n",
        "{\n",
        "  int tid = threadIdx.x + blockDim.x*blockIdx.x;\n",
        "\n",
        "  x[tid] = (float) threadIdx.x;\n",
        "}\n",
        "\n",
        "\n",
        "//\n",
        "// main code\n",
        "//\n",
        "\n",
        "int main(int argc, const char **argv)\n",
        "{\n",
        "  float *h_x, *d_x;\n",
        "  int   nblocks, nthreads, nsize, n;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // set number of blocks, and threads per block\n",
        "\n",
        "  nblocks  = 2;\n",
        "  nthreads = 8;\n",
        "  nsize    = nblocks*nthreads ;\n",
        "\n",
        "  // allocate memory for array\n",
        "\n",
        "  h_x = (float *)malloc(nsize*sizeof(float));\n",
        "  checkCudaErrors(cudaMalloc((void **)&d_x, nsize*sizeof(float)));\n",
        "\n",
        "  // execute kernel\n",
        "\n",
        "  my_first_kernel<<<nblocks,nthreads>>>(d_x);\n",
        "  getLastCudaError(\"my_first_kernel execution failed\\n\");\n",
        "\n",
        "  // copy back results and print them out\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(h_x,d_x,nsize*sizeof(float),\n",
        "                 cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  for (n=0; n<nsize; n++) printf(\" n,  x  =  %d  %f \\n\",n,h_x[n]);\n",
        "\n",
        "  // free memory\n",
        "\n",
        "  checkCudaErrors(cudaFree(d_x));\n",
        "  free(h_x);\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e977fe48-cd26-4458-b9bf-7856f3d5a993",
        "id": "vThsmRu7_7Zh"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prac1b.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac1b.cu -o prac1b -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcYvbrFvAEM-",
        "outputId": "9edfc05a-c4c7-4ddf-fca7-39b4fe0a6a35"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z15my_first_kernelPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z15my_first_kernelPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 10 registers, 360 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac1b"
      ],
      "metadata": {
        "id": "XFHWm4Dd3_hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac274d2-f989-472f-8261-9ac2863e09c0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            " n,  x  =  0  0.000000 \n",
            " n,  x  =  1  1.000000 \n",
            " n,  x  =  2  2.000000 \n",
            " n,  x  =  3  3.000000 \n",
            " n,  x  =  4  4.000000 \n",
            " n,  x  =  5  5.000000 \n",
            " n,  x  =  6  6.000000 \n",
            " n,  x  =  7  7.000000 \n",
            " n,  x  =  8  0.000000 \n",
            " n,  x  =  9  1.000000 \n",
            " n,  x  =  10  2.000000 \n",
            " n,  x  =  11  3.000000 \n",
            " n,  x  =  12  4.000000 \n",
            " n,  x  =  13  5.000000 \n",
            " n,  x  =  14  6.000000 \n",
            " n,  x  =  15  7.000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac1b.cu\n",
        "\n",
        "//\n",
        "// include files\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "\n",
        "//\n",
        "// kernel routine\n",
        "//\n",
        "\n",
        "__global__ void my_first_kernel(float *a,float *b,float *c)\n",
        "{\n",
        "  int tid = threadIdx.x + blockDim.x*blockIdx.x;\n",
        "\n",
        "  c[tid] = (float) a[tid]+b[tid];\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "//\n",
        "// main code\n",
        "//\n",
        "\n",
        "int main(int argc, const char **argv)\n",
        "{\n",
        "  float h_a[16] ={10,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16};\n",
        "  float h_b[16] ={1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16};\n",
        "  float *d_c,*d_a,*d_b;\n",
        "  float *h_c;\n",
        "  int   nblocks, nthreads, nsize, n;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // set number of blocks, and threads per block\n",
        "\n",
        "  nblocks  = 2;\n",
        "  nthreads = 8;\n",
        "  nsize    = nblocks*nthreads ;\n",
        "\n",
        "  // allocate memory for array\n",
        "\n",
        "  h_c = (float *)malloc(nsize*sizeof(float));\n",
        "  checkCudaErrors(cudaMalloc((void **)&d_a, nsize*sizeof(float)));\n",
        "  checkCudaErrors(cudaMalloc((void **)&d_b, nsize*sizeof(float)));\n",
        "  checkCudaErrors(cudaMalloc((void **)&d_c, nsize*sizeof(float)));\n",
        "\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(d_a,h_a,nsize*sizeof(float),\n",
        "                 cudaMemcpyDefault) );\n",
        "  checkCudaErrors( cudaMemcpy(d_b,h_b,nsize*sizeof(float),\n",
        "                 cudaMemcpyDefault) );\n",
        "  // execute kernel\n",
        "\n",
        "  my_first_kernel<<<nblocks,nthreads>>>(d_a,d_b,d_c);\n",
        "  getLastCudaError(\"my_first_kernel execution failed\\n\");\n",
        "\n",
        "  // copy back results and print them out\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(h_c,d_c,nsize*sizeof(float),\n",
        "                 cudaMemcpyDefault) );\n",
        "\n",
        "  for (n=0; n<nsize; n++) printf(\" n,  c  =  %d  %f \\n\",n,h_c[n]);\n",
        "\n",
        "  // free memory\n",
        "\n",
        "  checkCudaErrors(cudaFree(d_a));\n",
        "\n",
        "  checkCudaErrors(cudaFree(d_b));\n",
        "\n",
        "  checkCudaErrors(cudaFree(d_c));\n",
        "  free(h_c);\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVNSrBxyJJ5F",
        "outputId": "d4282c37-7b06-4107-afc4-66fa92f81b7c"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prac1b.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac1b.cu -o prac1b -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk5I2Rc7M_O2",
        "outputId": "288a6192-d40f-4a5a-85c2-8a9703143b94"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z15my_first_kernelPfS_S_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z15my_first_kernelPfS_S_\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 12 registers, 376 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac1b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4OMji6QM_Wg",
        "outputId": "ec7cf787-dfd5-4803-f9cb-c702a1f478bd"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            " n,  c  =  0  11.000000 \n",
            " n,  c  =  1  4.000000 \n",
            " n,  c  =  2  6.000000 \n",
            " n,  c  =  3  8.000000 \n",
            " n,  c  =  4  10.000000 \n",
            " n,  c  =  5  12.000000 \n",
            " n,  c  =  6  14.000000 \n",
            " n,  c  =  7  16.000000 \n",
            " n,  c  =  8  18.000000 \n",
            " n,  c  =  9  20.000000 \n",
            " n,  c  =  10  22.000000 \n",
            " n,  c  =  11  24.000000 \n",
            " n,  c  =  12  26.000000 \n",
            " n,  c  =  13  28.000000 \n",
            " n,  c  =  14  30.000000 \n",
            " n,  c  =  15  32.000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "By going back to the previous code blocks you can modify the codes to complete the Practical 1 exercises.  Alternatively you can copy a Code cell (on my system I do this by using the mouse right-click) and paste it (control-V on my system) to form a new Code cell -- this is best for the final exercise in which you are to write a new code to add two vectors.\n",
        "\n",
        "However, this copy of the notebook is read-only for everyone except the owner (me!) so you will need to make your own copy of the notebook by going to the File option at the top and then clicking on \"Save a copy in Drive\" which will make a copy of it in your Google Drive.  You are then the owner of the copy and can edit it freely.\n",
        "\n",
        "For students doing this as an assignment to be assessed, you should add your name to the title of the notebook (as in \"Practical 1 -- Mike Giles.ipynb\"), make it shared (see the Share option in the top-right corner) and provide the shared link as the submission mechanism."
      ],
      "metadata": {
        "id": "ncymVLmd4L82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This final piece of code terminates the runtime for this notebook so that you can switch to a new notebook without any problems -- you will get an error message if you try to keep two runtimes going at the same time with the free Colab account.\n",
        "\n",
        "It's particularly convenient if you are executing the whole notebook to check everything works correctly, using the \"Run all\" option in the Runtime tab."
      ],
      "metadata": {
        "id": "qwBJXY68f9W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "XFPuNsfygVaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}